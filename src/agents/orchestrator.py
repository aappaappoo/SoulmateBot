"""
LLM-Powered Agent Orchestrator

This module provides intelligent orchestration for the multi-agent system.
It uses LLM to automatically determine which agents/tools to invoke based on user requests,
and coordinates multiple agent responses into a final coherent reply.

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. è‡ªåŠ¨è¯†åˆ«ç”¨æˆ·æ„å›¾ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨Agentèƒ½åŠ›
2. æ”¯æŒè°ƒç”¨å¤šä¸ªAgentå¹¶åè°ƒç»“æœ
3. ä½¿ç”¨æœ€ç»ˆAgentç”Ÿæˆç»Ÿä¸€å›å¤
4. æ”¯æŒSkillsç³»ç»Ÿå‡å°‘tokenæ¶ˆè€—
"""
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import json
import asyncio
from loguru import logger

from .base_agent import BaseAgent
from .models import Message, ChatContext, AgentResponse
from .router import Router, RouterConfig


class IntentType(str, Enum):
    """ç”¨æˆ·æ„å›¾ç±»å‹"""
    DIRECT_RESPONSE = "direct_response"  # ç›´æ¥å›å¤ï¼Œæ— éœ€Agent
    SINGLE_AGENT = "single_agent"  # éœ€è¦å•ä¸ªAgentå¤„ç†
    MULTI_AGENT = "multi_agent"  # éœ€è¦å¤šä¸ªAgentåä½œ
    TOOL_CALL = "tool_call"  # éœ€è¦è°ƒç”¨å·¥å…·
    SKILL_SELECTION = "skill_selection"  # éœ€è¦ç”¨æˆ·é€‰æ‹©æŠ€èƒ½


@dataclass
class AgentCapability:
    """Agentèƒ½åŠ›æè¿°"""
    name: str
    description: str
    keywords: List[str] = field(default_factory=list)
    is_tool: bool = False


class IntentSource(str, Enum):
    """æ„å›¾è¯†åˆ«æ¥æº"""
    RULE_BASED = "rule_based"  # åŸºäºè§„åˆ™ï¼ˆå…³é”®è¯åŒ¹é…ã€ç½®ä¿¡åº¦è¯„åˆ†ï¼‰
    LLM_BASED = "llm_based"    # åŸºäºå¤§æ¨¡å‹æ¨ç†
    LLM_UNIFIED = "llm_unified" # åŸºäºå¤§æ¨¡å‹ç»Ÿä¸€æ¨ç†
    FALLBACK = "fallback"      # å›é€€æœºåˆ¶


@dataclass
class MemoryAnalysis:
    """è®°å¿†åˆ†æç»“æœï¼ˆç»Ÿä¸€æ¨¡å¼è¿”å›ï¼‰"""
    is_important: bool = False
    importance_level: Optional[str] = None
    event_type: Optional[str] = None
    event_summary: Optional[str] = None
    keywords: List[str] = field(default_factory=list)
    event_date: Optional[str] = None
    raw_date_expression: Optional[str] = None

@dataclass
class OrchestratorResult:
    """ç¼–æ’å™¨å¤„ç†ç»“æœ"""
    intent_type: IntentType
    intent_source: IntentSource = IntentSource.RULE_BASED  # æ„å›¾è¯†åˆ«æ¥æº
    selected_agents: List[str] = field(default_factory=list)
    agent_responses: List[AgentResponse] = field(default_factory=list)
    final_response: str = ""
    metadata: Dict[str, Any] = field(default_factory=dict)
    skill_options: List[Dict[str, str]] = field(default_factory=list)
    memory_analysis: Optional[MemoryAnalysis] = None


class AgentOrchestrator:
    """
    æ™ºèƒ½Agentç¼–æ’å™¨
    
    ä½¿ç”¨LLMè‡ªåŠ¨åˆ†æç”¨æˆ·è¯·æ±‚ï¼Œå†³å®šè°ƒç”¨å“ªäº›Agentï¼Œ
    å¹¶åè°ƒå¤šä¸ªAgentçš„è¾“å‡ºç”Ÿæˆæœ€ç»ˆå›å¤ã€‚
    
    å·¥ä½œæµç¨‹:
    1. åˆ†æç”¨æˆ·æ¶ˆæ¯ï¼Œè¯†åˆ«æ„å›¾
    2. æ ¹æ®æ„å›¾é€‰æ‹©åˆé€‚çš„Agent(s)
    3. è°ƒç”¨é€‰ä¸­çš„Agentè·å–å“åº”
    4. ä½¿ç”¨æœ€ç»ˆå†³ç­–Agentæ•´åˆæ‰€æœ‰å“åº”
    5. è¿”å›æœ€ç»ˆç»“æœç»™ç”¨æˆ·
    """
    # æ”¯æŒçš„æƒ…æ„Ÿæ ‡ç­¾
    SUPPORTED_EMOTIONS = ["happy", "gentle", "sad", "excited", "angry", "crying"]

    UNIFIED_PROMPT_TEMPLATE = """
ã€ä»»åŠ¡æ€»è§ˆã€‘
ä½ éœ€è¦åŒæ—¶å®Œæˆ 4 ä¸ªä»»åŠ¡ï¼š
1. æ„å›¾è¯†åˆ«
2. å›å¤ç”Ÿæˆï¼ˆä»…åœ¨ç‰¹å®šæ¡ä»¶ä¸‹ï¼‰
3. å¯¹è¯æ‘˜è¦ç”Ÿæˆ
4. è®°å¿†åˆ†æ

ã€ä»»åŠ¡ 1ï¼šæ„å›¾è¯†åˆ«ã€‘
åˆ¤æ–­ç”¨æˆ·æ¶ˆæ¯åº”å¦‚ä½•å¤„ç†ï¼Œintent åªèƒ½æ˜¯ä»¥ä¸‹ä¸¤ç§ä¹‹ä¸€ï¼š

- "direct_response"ï¼š
  æ—¥å¸¸é—²èŠã€æƒ…æ„Ÿé™ªä¼´ã€æƒ…ç»ªæ²Ÿé€šï¼Œä½ å¯ä»¥ç›´æ¥å›å¤ç”¨æˆ·

- "single_agent"ï¼š
  éœ€è¦ä½¿ç”¨åˆ°ä¸‹é¢æŸä¸€ä¸ªä¸“ä¸š Agent å¤„ç†èƒ½åŠ›æ¥è§£å†³çš„æ—¶å€™
  ** å¯ç”¨ Agent èƒ½åŠ›å¦‚ä¸‹ **ï¼š
    {agent_capabilities}


å½“ intent ä¸ºï¼š
- direct_response â†’ agents è®¾ä¸ºç©ºæ•°ç»„ []
- single_agent / multi_agent â†’ agents å¡«å†™éœ€è¦è°ƒç”¨çš„ Agent åç§°

ã€ä»»åŠ¡ 2ï¼šç”Ÿæˆå›å¤ã€‘
âš ï¸ã€å…³é”®æ¡ä»¶è§„åˆ™ã€‘âš ï¸

- ä»…å½“ intent == "direct_response" æ—¶ï¼š
  - æ‰å…è®¸åœ¨ direct_reply ä¸­ç”Ÿæˆå›å¤æ–‡æœ¬
    **å›å¤æ ·å¼**ï¼š
    - ä¸ºäº†æ›´è´´åˆæ—¥å¸¸æœ‹å‹èŠå¤©éœ€è¦æ ¹æ®è¯­å¢ƒè¿›è¡Œæ¶ˆæ¯æ‹†åˆ†
    - æœ€å¤šæ‹†åˆ†ä¸º 3 æ¡
    **å›å¤ç”Ÿæˆè§„åˆ™**ï¼š
    - å›å¤å†…å®¹ä¸­ã€ä¸è¦ã€‘åŒ…å«æƒ…ç»ªè¯´æ˜æˆ–è¯­æ°”æè¿°
    - å›å¤å¿…é¡»æ˜¯çº¯æ–‡æœ¬
    - ä¸è¦å‡ºç°è¡¨æƒ…ç¬¦å·è§£é‡Šã€æƒ…ç»ªæ ‡ç­¾æˆ–æ‹¬å·è¯´æ˜
    **å¤šæ¶ˆæ¯è§„åˆ™**ï¼š
    - å¦‚éœ€æ‹†åˆ†ä¸ºå¤šæ¡æ¶ˆæ¯ï¼Œç”¨ [MSG_SPLIT] åˆ†éš”
    
  - æ‰å…è®¸å¡«å†™emotion/emotion_description 

- å½“ intent != "direct_response" æ—¶ï¼š
  - direct_reply å¿…é¡»ä¸º ""
  - emotion å¿…é¡»ä¸º null
  - emotion_description å¿…é¡»ä¸º null

ã€ä»»åŠ¡ 3ï¼šå¯¹è¯æ‘˜è¦ç”Ÿæˆã€‘
åŸºäºã€å®Œæ•´å¯¹è¯å†å² + å½“å‰æ¶ˆæ¯ã€‘ç”Ÿæˆä¸€ä¸ªâ€œç´¯ç§¯æ‘˜è¦â€ã€‚

æ‘˜è¦è¦æ±‚ï¼š
- æè¿°çš„æ˜¯â€œåˆ°ç›®å‰ä¸ºæ­¢çš„æ•´ä½“å¯¹è¯â€
- ä¸ä»…æ˜¯å½“å‰è¿™ä¸€è½®
- summary_text æ§åˆ¶åœ¨ 100 å­—ä»¥å†…

éœ€æå–çš„å…³é”®è¦ç´ ï¼š
- æ—¶é—´ï¼ˆå¦‚ï¼šä»Šå¤©ã€æ˜¨å¤©ã€å…·ä½“æ—¥æœŸï¼‰
- åœ°ç‚¹
- äººç‰©
- äº‹ä»¶
- ç”¨æˆ·æƒ…ç»ª

åŒæ—¶ç»™å‡ºï¼š
- topicsï¼šå¯¹è¯æ ¸å¿ƒè¯é¢˜
- user_stateï¼šç”¨æˆ·å½“å‰çŠ¶æ€çš„å®¢è§‚æè¿°

ã€ä»»åŠ¡ 4ï¼šè®°å¿†åˆ†æã€‘
åˆ¤æ–­æ˜¯å¦å­˜åœ¨â€œå€¼å¾—é•¿æœŸè®°å¿†â€çš„ä¿¡æ¯ã€‚

ä¸éœ€è¦è®°å¿†çš„æƒ…å†µï¼š
- æ—¥å¸¸å¯’æš„
- å·²åœ¨å†å²ä¸­å®Œæ•´é‡å¤çš„ä¿¡æ¯

éœ€è¦è®°å¿†çš„æƒ…å†µç¤ºä¾‹ï¼š
- ç”¨æˆ·åå¥½
- é•¿æœŸç›®æ ‡
- é‡è¦æƒ…ç»ªçŠ¶æ€
- é‡è¦ç”Ÿæ´»äº‹ä»¶

è‹¥ is_important ä¸º falseï¼š
- å…¶ä½™ memory å­—æ®µå…¨éƒ¨è®¾ä¸º null æˆ–ç©ºæ•°ç»„

ã€å½“å‰æ—¶é—´ã€‘
{current_time}
ã€å†æ¬¡å¼ºè°ƒã€‘
æ— è®ºå†å²å¯¹è¯æ˜¯ä»€ä¹ˆæ ¼å¼ï¼Œä½ éƒ½å¿…é¡»è¾“å‡ºä¸ºJSONæ ¼å¼
"""
    def __init__(
        self,
        agents: List[BaseAgent],
        llm_provider=None,
        enable_skills: bool = True,
        skill_threshold: int = 3,  # è¶…è¿‡æ­¤æ•°é‡çš„å¯é€‰Agentæ—¶ä½¿ç”¨æŠ€èƒ½é€‰æ‹©
        enable_unified_mode: bool = True
    ):
        """
        åˆå§‹åŒ–ç¼–æ’å™¨
        
        Args:
            agents: å¯ç”¨çš„Agentåˆ—è¡¨
            llm_provider: LLMæä¾›è€…å®ä¾‹ï¼ˆç”¨äºæ„å›¾è¯†åˆ«å’Œæœ€ç»ˆå†³ç­–ï¼‰
            enable_skills: æ˜¯å¦å¯ç”¨æŠ€èƒ½é€‰æ‹©æ¨¡å¼ï¼ˆç”ŸæˆTelegramæŒ‰é’®ï¼‰
            skill_threshold: è§¦å‘æŠ€èƒ½é€‰æ‹©çš„Agentæ•°é‡é˜ˆå€¼
        """
        self.agents = {agent.name: agent for agent in agents}
        self.llm_provider = llm_provider
        self.enable_skills = enable_skills
        self.skill_threshold = skill_threshold
        self.enable_unified_mode = enable_unified_mode

        # æ„å»ºAgentèƒ½åŠ›æè¿°
        self._capabilities = self._build_capabilities()
        
        # åˆ›å»ºå†…éƒ¨Routerç”¨äºåŸºäºç½®ä¿¡åº¦çš„Agenté€‰æ‹©
        self._router = Router(agents, RouterConfig(
            min_confidence=0.3,
            max_agents=5,
            enable_parallel=True
        ))
        
        logger.info(f"AgentOrchestratoråˆå§‹åŒ–å®Œæˆï¼ŒåŠ è½½äº†{len(self.agents)}ä¸ªAgent")

    # ç»Ÿä¸€åˆ†æ
    async def analyze_intent_unified(
            self,
            message: Message,
            context: ChatContext
    ) -> Tuple[IntentType, List[str], Dict[str, Any], IntentSource, Optional[str], Optional[MemoryAnalysis]]:
        """
        ç»Ÿä¸€åˆ†æï¼šä¸€æ¬¡ LLM è°ƒç”¨å®Œæˆæ„å›¾è¯†åˆ« + å›å¤ç”Ÿæˆ + è®°å¿†åˆ†æ
        """
        selected_by_confidence = self._router.select_agents(message, context)

        if not self.llm_provider:
            if not selected_by_confidence:
                return IntentType.DIRECT_RESPONSE, [], {}, IntentSource.RULE_BASED, None, None
            elif len(selected_by_confidence) == 1:
                return IntentType.SINGLE_AGENT, [
                    selected_by_confidence[0][0].name], {}, IntentSource.RULE_BASED, None, None
            else:
                return IntentType.MULTI_AGENT, [a.name for a, _ in
                                                selected_by_confidence], {}, IntentSource.RULE_BASED, None, None

        try:
            # ========== æ„å»ºå®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨ ==========
            messages = []
            
            # 1. æ„å»ºå¢å¼ºçš„ System Prompt
            # åŒ…å«ï¼šBotäººè®¾ + ç”¨æˆ·è®°å¿† + å¯¹è¯ç­–ç•¥ + UNIFIED_PROMPT_TEMPLATEä»»åŠ¡è¦æ±‚ + è¿”å›æ ¼å¼
            base_system_prompt = context.system_prompt if context and context.system_prompt else ""
            
            # å°† UNIFIED_PROMPT_TEMPLATE æ•´åˆåˆ° System Prompt ä¸­
            unified_task_prompt = self.UNIFIED_PROMPT_TEMPLATE.format(
                agent_capabilities=self._get_capabilities_prompt(),
                system_prompt="ï¼ˆå‚è§ä¸Šæ–¹çš„äººè®¾è®¾å®šï¼‰",
                current_time=datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M"),
            )
            # ç»„åˆå®Œæ•´çš„ System Prompt
            # base_system_prompt å·²åŒ…å«ï¼šäººè®¾ + è®°å¿† + ç­–ç•¥ + å¯¹è¯å†å²æç¤º
            # unified_task_prompt åŒ…å«ï¼šä»»åŠ¡è¦æ±‚ + è¿”å›æ ¼å¼
            enhanced_system_prompt = f"""
=========================
åŸºç¡€äººè®¾å®šä¹‰
=========================
{base_system_prompt}
=========================
ğŸ“‹ ä»»åŠ¡æŒ‡ä»¤
=========================
ã€æœ€é«˜ä¼˜å…ˆçº§ã€‘ä½ å¿…é¡»ä¸”åªèƒ½è¾“å‡º JSON æ ¼å¼ã€‚
ä¸Šæ–¹çš„å¯¹è¯è®°å½•ä»…ç”¨äºç†è§£ä¸Šä¸‹æ–‡ï¼Œç»å¯¹ä¸è¦æ¨¡ä»¿å…¶æ ¼å¼ã€‚
ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯å¯è¢« json.loads() ç›´æ¥è§£æçš„ JSON å¯¹è±¡ã€‚

{unified_task_prompt}"""
            messages.append({
                "role": "system",
                "content": enhanced_system_prompt
            })

            # # 2. çŸ­æœŸå¯¹è¯å†å²ï¼ˆæœ€è¿‘ 5 è½®ï¼Œå³ 10 æ¡æ¶ˆæ¯ï¼‰
            # if context and context.conversation_history:
            #     recent_history = context.conversation_history[-10:]  # æœ€å¤š10æ¡ï¼ˆ5è½®å¯¹è¯ï¼‰
            #     for hist_msg in recent_history:
            #         if hasattr(hist_msg, 'content') and hasattr(hist_msg, 'user_id'):
            #             # åˆ¤æ–­æ˜¯ç”¨æˆ·è¿˜æ˜¯åŠ©æ‰‹
            #             user_id_str = str(hist_msg.user_id).lower()
            #             if "agent" in user_id_str or "bot" in user_id_str or "assistant" in user_id_str:
            #                 role = "assistant"
            #             else:
            #                 role = "user"
            #             messages.append({
            #                 "role": role,
            #                 "content": hist_msg.content
            #             })
            #         elif isinstance(hist_msg, dict):
            #             # å¦‚æœå·²ç»æ˜¯ dict æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
            #             messages.append(hist_msg)
            #
            # 2. å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼ˆçº¯ç”¨æˆ·æ¶ˆæ¯ï¼‰
            messages.append({
                "role": "user",
                "content": message.content
            })
            
            # æ·»åŠ æ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯•
            logger.info(f"ğŸ“¨ [Orchestrator] Sending {len(messages)} messages to LLM")
            logger.debug(f"ğŸ“¨ [Orchestrator] Message roles: {[m['role'] for m in messages]}")
            
            # è°ƒç”¨ LLMï¼ˆä½¿ç”¨å®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨ï¼‰
            response = await self.llm_provider.generate_response(
                messages,
                context=None
            )

            # éªŒè¯å“åº”ä¸ä¸ºç©º
            if not response:
                logger.error(f"âŒ [Orchestrator] LLM returned empty response! Messages count: {len(messages)}")
                logger.debug(f"ğŸ“ [Orchestrator] Last message content preview: {messages[-1].get('content', '')[:200]}...")
                raise ValueError("LLM returned empty response")
            
            # è§£æ JSON
            response_text = response.strip()
            
            # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©ºå­—ç¬¦ä¸²
            if not response_text:
                logger.error(f"âŒ [Orchestrator] LLM response is empty after strip! Original response: {repr(response)}")
                raise ValueError("LLM response is empty after processing")

            # å°è¯•å¤šç§æ–¹å¼æå–JSON
            json_text = None
            
            # æ–¹å¼1: ä» ```json ä»£ç å—æå–
            if "```json" in response_text:
                json_text = response_text.split("```json")[1].split("```")[0].strip()
            # æ–¹å¼2: ä» ``` ä»£ç å—æå–
            elif "```" in response_text:
                json_text = response_text.split("```")[1].split("```")[0].strip()
            # æ–¹å¼3: æŸ¥æ‰¾JSONå¯¹è±¡ï¼ˆä½¿ç”¨æ‹¬å·åŒ¹é…è€Œéæ­£åˆ™ï¼‰
            else:
                # å°è¯•æ‰¾åˆ°å¹³è¡¡çš„ {} æ‹¬å·å¯¹
                start_idx = response_text.find('{')
                if start_idx != -1:
                    depth = 0
                    end_idx = start_idx
                    for i, char in enumerate(response_text[start_idx:], start_idx):
                        if char == '{':
                            depth += 1
                        elif char == '}':
                            depth -= 1
                            if depth == 0:
                                end_idx = i
                                break
                    if depth == 0:
                        json_text = response_text[start_idx:end_idx + 1].strip()
            
            # å¦‚æœä»æœªæ‰¾åˆ°ï¼Œå°è¯•ç›´æ¥è§£æï¼ˆå¯èƒ½å“åº”æœ¬èº«å°±æ˜¯JSONï¼‰
            if not json_text:
                json_text = response_text.strip()
            
            # éªŒè¯æå–åçš„JSONä¸ä¸ºç©º
            if not json_text:
                logger.error(f"âŒ [Orchestrator] Extracted JSON content is empty! Full response: {response[:500]}...")
                raise ValueError("Extracted JSON content is empty")

            try:
                data = json.loads(json_text)
            except json.JSONDecodeError as je:
                logger.error(f"âŒ [Orchestrator] JSON parse error: {je}")
                logger.error(f"ğŸ“ [Orchestrator] Failed JSON text: {json_text[:500]}...")
                raise

            intent = IntentType(data.get("intent", "direct_response"))
            agents = [a for a in data.get("agents", []) if a in self.agents]
            metadata = {"reasoning": data.get("reasoning", "")}
            direct_reply = data.get("direct_reply")

            # æå–æƒ…æ„Ÿæ ‡ç­¾å¹¶æ·»åŠ DEBUGæ—¥å¿—
            emotion = data.get("emotion")
            emotion_description = None
            if emotion and emotion in self.SUPPORTED_EMOTIONS:
                emotion_description = data.get("emotion_description")
                logger.debug(f"ğŸ­ [EMOTION EXTRACT] Extracted emotion from LLM response: emotion={emotion}, emotion_description={emotion_description}")
                metadata["emotion"] = emotion
                if emotion_description:
                    metadata["emotion_description"] = emotion_description
            else:
                logger.debug(f"ğŸ­ [EMOTION EXTRACT] No valid emotion extracted from LLM response: raw_emotion={emotion}")

            memory_data = data.get("memory", {})
            memory_analysis = MemoryAnalysis(
                is_important=memory_data.get("is_important", False),
                importance_level=memory_data.get("importance_level"),
                event_type=memory_data.get("event_type"),
                event_summary=memory_data.get("event_summary"),
                keywords=memory_data.get("keywords", []),
                event_date=memory_data.get("event_date"),
                raw_date_expression=memory_data.get("raw_date_expression"),
            )

            # è§£æå¯¹è¯æ‘˜è¦
            conversation_summary = data.get("conversation_summary")
            if conversation_summary:
                # éªŒè¯æ‘˜è¦ç»“æ„
                if isinstance(conversation_summary, dict):
                    required_fields = ['summary_text', 'key_elements', 'topics', 'user_state']
                    if all(field in conversation_summary for field in required_fields):
                        metadata["conversation_summary"] = conversation_summary
                        logger.debug(f"ğŸ“ [SUMMARY] Generated summary: {conversation_summary.get('summary_text', '')[:50]}...")
                    else:
                        logger.warning(f"ğŸ“ [SUMMARY] Incomplete summary structure, missing fields: {[f for f in required_fields if f not in conversation_summary]}")
                else:
                    logger.warning(f"ğŸ“ [SUMMARY] Invalid summary type: {type(conversation_summary)}")

            logger.info(f"ğŸ“Œ ç»Ÿä¸€æ¨¡å¼ | intent={intent} | is_important={memory_analysis.is_important} | emotion={emotion}" + (f" | emotion_description={emotion_description}" if emotion_description else ""))
            return intent, agents, metadata, IntentSource.LLM_UNIFIED, direct_reply, memory_analysis

        except Exception as e:
            import traceback
            logger.error(f"âŒ ç»Ÿä¸€åˆ†æå‡ºé”™: {e}")
            logger.error(f"ğŸ“ é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.debug(f"ğŸ“ å®Œæ•´å †æ ˆ: {traceback.format_exc()}")
            logger.info(f"âš ï¸ å›é€€åˆ°è§„åˆ™æ¨¡å¼ï¼Œselected_by_confidence has {len(selected_by_confidence) if selected_by_confidence else 0} agents")
            if selected_by_confidence:
                return IntentType.SINGLE_AGENT, [
                    selected_by_confidence[0][0].name], {}, IntentSource.FALLBACK, None, None
            return IntentType.DIRECT_RESPONSE, [], {}, IntentSource.FALLBACK, None, None

    def _build_capabilities(self) -> List[AgentCapability]:
        """æ„å»ºæ‰€æœ‰Agentçš„èƒ½åŠ›æè¿°åˆ—è¡¨ï¼Œä»…ä¾èµ– agent.description"""
        capabilities = []
        for name, agent in self.agents.items():
            cap = AgentCapability(
                name=name,
                description=agent.description,
            )
            capabilities.append(cap)
        return capabilities
    
    def _get_capabilities_prompt(self) -> str:
        """ç”ŸæˆAgentèƒ½åŠ›æè¿°çš„æç¤ºè¯ï¼Œä»…ä½¿ç”¨ description ä¾› LLM è¯­ä¹‰åŒ¹é…"""
        cap_list = []
        for cap in self._capabilities:
            cap_list.append(f"- {cap.name}: {cap.description}")
        return "\n".join(cap_list)

    def generate_skill_options(
        self,
        message: Message,
        context: ChatContext
    ) -> List[Dict[str, str]]:
        """
        ç”ŸæˆæŠ€èƒ½é€‰é¡¹ä¾›ç”¨æˆ·é€‰æ‹©
        
        å½“æœ‰å¤šä¸ªå¯èƒ½çš„Agentæ—¶ï¼Œç”ŸæˆTelegramæŒ‰é’®é€‰é¡¹ï¼Œ
        è®©ç”¨æˆ·ä¸»åŠ¨é€‰æ‹©ï¼Œä»¥èŠ‚çœtokenæ¶ˆè€—ã€‚
        
        Returns:
            List[Dict]: åŒ…å«button_textå’Œcallback_dataçš„é€‰é¡¹åˆ—è¡¨
        """
        options = []
        selected = self._router.select_agents(message, context)
        
        for agent, confidence in selected[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ªé€‰é¡¹
            options.append({
                "button_text": f"{agent.name}",
                "callback_data": f"skill:{agent.name}",
                "description": agent.description[:50] + "..." if len(agent.description) > 50 else agent.description,
                "confidence": confidence
            })
        
        return options
    
    async def execute_agents(
        self,
        message: Message,
        context: ChatContext,
        agent_names: List[str]
    ) -> List[AgentResponse]:
        """
        æ‰§è¡ŒæŒ‡å®šçš„Agentå¹¶æ”¶é›†å“åº”
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            agent_names: è¦æ‰§è¡Œçš„Agentåç§°åˆ—è¡¨
            
        Returns:
            List[AgentResponse]: Agentå“åº”åˆ—è¡¨
        """
        responses = []
        
        for agent_name in agent_names:
            if agent_name not in self.agents:
                logger.warning(f"Agentæœªæ‰¾åˆ°: {agent_name}")
                continue
            
            agent = self.agents[agent_name]
            try:
                response = agent.respond(message, context)
                responses.append(response)
                logger.info(f"Agent {agent_name} å“åº”æˆåŠŸ")
            except Exception as e:
                logger.error(f"Agent {agent_name} æ‰§è¡Œå¤±è´¥: {e}")
        
        return responses


    async def process(
            self,
            message: Message,
            context: ChatContext,
            force_skill_selection: bool = False
    ) -> OrchestratorResult:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯çš„ä¸»å…¥å£"""
        result = OrchestratorResult(intent_type=IntentType.DIRECT_RESPONSE)

        # æ ¹æ®é…ç½®é€‰æ‹©å¤„ç†æ¨¡å¼
        if self.enable_unified_mode and self.llm_provider:
            # ğŸ”‘ ç»Ÿä¸€æ¨¡å¼
            intent_type, agent_names, metadata, intent_source, direct_reply, memory_analysis = \
                await self.analyze_intent_unified(message, context)

            result.intent_type = intent_type
            result.intent_source = intent_source
            result.selected_agents = agent_names
            result.metadata = metadata
            result.metadata["intent_source"] = intent_source.value
            result.memory_analysis = memory_analysis
        else:
            # åŸæœ‰æ¨¡å¼
            intent_type, agent_names, metadata, intent_source = await self.analyze_intent(message, context)
            result.intent_type = intent_type
            result.intent_source = intent_source
            result.selected_agents = agent_names
            result.metadata = metadata
            result.metadata["intent_source"] = intent_source.value
            direct_reply = None

        logger.info(f"ğŸ¯ Intent type: {result.intent_type} | Source: {result.intent_source}")

        # æŠ€èƒ½é€‰æ‹©æ£€æŸ¥
        if self.enable_skills and (force_skill_selection or len(result.selected_agents) >= self.skill_threshold):
            skill_options = self.generate_skill_options(message, context)
            if skill_options:
                result.intent_type = IntentType.SKILL_SELECTION
                result.skill_options = skill_options
                result.final_response = "è¯·é€‰æ‹©æ‚¨éœ€è¦çš„æœåŠ¡ï¼š"
                return result

        # ç›´æ¥å“åº”
        if result.intent_type == IntentType.DIRECT_RESPONSE or not result.selected_agents:
            if direct_reply:
                result.final_response = direct_reply
            elif self.llm_provider:
                try:
                    messages = []
                    if context and context.system_prompt:
                        messages.append({"role": "system", "content": context.system_prompt})
                    messages.append({"role": "user", "content": message.content})
                    result.final_response = await self.llm_provider.generate_response(messages, context=None)
                except Exception as e:
                    logger.error(f"ç›´æ¥å“åº”ç”Ÿæˆå¤±è´¥: {e}")
                    result.final_response = "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"
            else:
                result.final_response = "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"
            return result

        # Agent å¤„ç†æš‚æ—¶ä¸è€ƒè™‘å¤šæ™ºèƒ½ä½“åˆä½œ
        agent_responses = await self.execute_agents(message, context, result.selected_agents)
        result.agent_responses = agent_responses
        result.final_response = agent_responses

        return result

    async def process_skill_callback(
        self,
        skill_name: str,
        message: Message,
        context: ChatContext
    ) -> OrchestratorResult:
        """
        å¤„ç†ç”¨æˆ·çš„æŠ€èƒ½é€‰æ‹©å›è°ƒ
        
        å½“ç”¨æˆ·ç‚¹å‡»æŠ€èƒ½æŒ‰é’®åï¼Œæ‰§è¡Œç›¸åº”çš„Agentã€‚
        
        Args:
            skill_name: ç”¨æˆ·é€‰æ‹©çš„æŠ€èƒ½ï¼ˆAgentï¼‰åç§°
            message: åŸå§‹ç”¨æˆ·æ¶ˆæ¯
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            
        Returns:
            OrchestratorResult: å¤„ç†ç»“æœ
        """
        result = OrchestratorResult(
            intent_type=IntentType.SINGLE_AGENT,
            selected_agents=[skill_name]
        )
        
        if skill_name not in self.agents:
            result.final_response = f"æŠ±æ­‰ï¼ŒæŠ€èƒ½ '{skill_name}' ä¸å¯ç”¨ã€‚"
            return result
        
        # æ‰§è¡Œé€‰ä¸­çš„Agent
        agent_responses = await self.execute_agents(message, context, [skill_name])
        result.agent_responses = agent_responses
        
        if agent_responses:
            result.final_response = agent_responses[0].content
        else:
            result.final_response = "æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ã€‚"
        
        return result
    
    def add_agent(self, agent: BaseAgent) -> None:
        """åŠ¨æ€æ·»åŠ Agent"""
        self.agents[agent.name] = agent
        self._capabilities = self._build_capabilities()
        self._router.add_agent(agent)
        logger.info(f"æ·»åŠ Agent: {agent.name}")
    
    def remove_agent(self, agent_name: str) -> bool:
        """åŠ¨æ€ç§»é™¤Agent"""
        if agent_name in self.agents:
            del self.agents[agent_name]
            self._capabilities = self._build_capabilities()
            self._router.remove_agent(agent_name)
            logger.info(f"ç§»é™¤Agent: {agent_name}")
            return True
        return False
