"""
LLM-Powered Agent Orchestrator

This module provides intelligent orchestration for the multi-agent system.
It uses LLM to automatically determine which agents/tools to invoke based on user requests,
and coordinates multiple agent responses into a final coherent reply.

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. è‡ªåŠ¨è¯†åˆ«ç”¨æˆ·æ„å›¾ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨Agentèƒ½åŠ›
2. æ”¯æŒè°ƒç”¨å¤šä¸ªAgentå¹¶åè°ƒç»“æœ
3. ä½¿ç”¨æœ€ç»ˆAgentç”Ÿæˆç»Ÿä¸€å›å¤
4. æ”¯æŒSkillsç³»ç»Ÿå‡å°‘tokenæ¶ˆè€—
"""
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import json
import asyncio
from loguru import logger

from .base_agent import BaseAgent
from .models import Message, ChatContext, AgentResponse
from .router import Router, RouterConfig


class IntentType(str, Enum):
    """ç”¨æˆ·æ„å›¾ç±»å‹"""
    DIRECT_RESPONSE = "direct_response"  # ç›´æ¥å›å¤ï¼Œæ— éœ€Agent
    SINGLE_AGENT = "single_agent"  # éœ€è¦å•ä¸ªAgentå¤„ç†
    MULTI_AGENT = "multi_agent"  # éœ€è¦å¤šä¸ªAgentåä½œ
    TOOL_CALL = "tool_call"  # éœ€è¦è°ƒç”¨å·¥å…·
    SKILL_SELECTION = "skill_selection"  # éœ€è¦ç”¨æˆ·é€‰æ‹©æŠ€èƒ½


@dataclass
class AgentCapability:
    """Agentèƒ½åŠ›æè¿°"""
    name: str
    description: str
    keywords: List[str] = field(default_factory=list)
    is_tool: bool = False


class IntentSource(str, Enum):
    """æ„å›¾è¯†åˆ«æ¥æº"""
    RULE_BASED = "rule_based"  # åŸºäºè§„åˆ™ï¼ˆå…³é”®è¯åŒ¹é…ã€ç½®ä¿¡åº¦è¯„åˆ†ï¼‰
    LLM_BASED = "llm_based"    # åŸºäºå¤§æ¨¡å‹æ¨ç†
    LLM_UNIFIED = "llm_unified" # åŸºäºå¤§æ¨¡å‹ç»Ÿä¸€æ¨ç†
    FALLBACK = "fallback"      # å›é€€æœºåˆ¶


@dataclass
class MemoryAnalysis:
    """è®°å¿†åˆ†æç»“æœï¼ˆç»Ÿä¸€æ¨¡å¼è¿”å›ï¼‰"""
    is_important: bool = False
    importance_level: Optional[str] = None
    event_type: Optional[str] = None
    event_summary: Optional[str] = None
    keywords: List[str] = field(default_factory=list)
    event_date: Optional[str] = None
    raw_date_expression: Optional[str] = None

@dataclass
class OrchestratorResult:
    """ç¼–æ’å™¨å¤„ç†ç»“æœ"""
    intent_type: IntentType
    intent_source: IntentSource = IntentSource.RULE_BASED  # æ„å›¾è¯†åˆ«æ¥æº
    selected_agents: List[str] = field(default_factory=list)
    agent_responses: List[AgentResponse] = field(default_factory=list)
    final_response: str = ""
    metadata: Dict[str, Any] = field(default_factory=dict)
    skill_options: List[Dict[str, str]] = field(default_factory=list)
    memory_analysis: Optional[MemoryAnalysis] = None


class AgentOrchestrator:
    """
    æ™ºèƒ½Agentç¼–æ’å™¨
    
    ä½¿ç”¨LLMè‡ªåŠ¨åˆ†æç”¨æˆ·è¯·æ±‚ï¼Œå†³å®šè°ƒç”¨å“ªäº›Agentï¼Œ
    å¹¶åè°ƒå¤šä¸ªAgentçš„è¾“å‡ºç”Ÿæˆæœ€ç»ˆå›å¤ã€‚
    
    å·¥ä½œæµç¨‹:
    1. åˆ†æç”¨æˆ·æ¶ˆæ¯ï¼Œè¯†åˆ«æ„å›¾
    2. æ ¹æ®æ„å›¾é€‰æ‹©åˆé€‚çš„Agent(s)
    3. è°ƒç”¨é€‰ä¸­çš„Agentè·å–å“åº”
    4. ä½¿ç”¨æœ€ç»ˆå†³ç­–Agentæ•´åˆæ‰€æœ‰å“åº”
    5. è¿”å›æœ€ç»ˆç»“æœç»™ç”¨æˆ·
    """
    # æ”¯æŒçš„æƒ…æ„Ÿæ ‡ç­¾
    SUPPORTED_EMOTIONS = ["happy", "gentle", "sad", "excited", "angry", "crying"]

    UNIFIED_PROMPT_TEMPLATE = """
è¯·æ ¹æ®è§„åˆ™å®Œæˆä»»åŠ¡ï¼Œå¹¶ã€åªè¾“å‡ºåˆæ³• JSONã€‘ã€‚
=========================
ã€æœ€é«˜ä¼˜å…ˆçº§ç¡¬çº¦æŸã€‘
=========================
1. ä½ ã€åªèƒ½ã€‘è¾“å‡º JSONï¼Œä¸å…è®¸åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€æ ‡ç‚¹æˆ–æ³¨é‡Š
2. JSON å¿…é¡»èƒ½è¢«æ ‡å‡† json.loads ç›´æ¥è§£æ
3. é™¤ direct_reply å­—æ®µå¤–ï¼Œç¦æ­¢ç”Ÿæˆä»»ä½•è‡ªç„¶è¯­è¨€å›å¤
4. ä¸¥æ ¼æŒ‰ç…§â€œå¼ºåˆ¶æ ¼å¼è¦æ±‚â€ä¸­çš„å­—æ®µè¿”å›ï¼Œä¸å¾—å¢å‡å­—æ®µ

=========================
ã€ä»»åŠ¡æ€»è§ˆã€‘
=========================
ä½ éœ€è¦åŒæ—¶å®Œæˆ 4 ä¸ªä»»åŠ¡ï¼š
1. æ„å›¾è¯†åˆ«
2. å›å¤ç”Ÿæˆï¼ˆä»…åœ¨ç‰¹å®šæ¡ä»¶ä¸‹ï¼‰
3. å¯¹è¯æ‘˜è¦ç”Ÿæˆ
4. è®°å¿†åˆ†æ

=========================
ã€ä»»åŠ¡ 1ï¼šæ„å›¾è¯†åˆ«ã€‘
=========================
åˆ¤æ–­ç”¨æˆ·æ¶ˆæ¯åº”å¦‚ä½•å¤„ç†ï¼Œintent åªèƒ½æ˜¯ä»¥ä¸‹ä¸‰ç§ä¹‹ä¸€ï¼š

- "direct_response"ï¼š
  æ—¥å¸¸é—²èŠã€é—®å€™ã€ç®€å•é—®ç­”ï¼Œä½ å¯ä»¥ç›´æ¥å›å¤ç”¨æˆ·

- "single_agent"ï¼š
  éœ€è¦æŸä¸€ä¸ªä¸“ä¸š Agent å¤„ç†çš„é—®é¢˜

- "multi_agent"ï¼š
  éœ€è¦å¤šä¸ª Agent åä½œçš„é—®é¢˜

å¯ç”¨ Agent èƒ½åŠ›å¦‚ä¸‹ï¼š
{agent_capabilities}

å½“ intent ä¸ºï¼š
- direct_response â†’ agents è®¾ä¸ºç©ºæ•°ç»„ []
- single_agent / multi_agent â†’ agents å¡«å†™éœ€è¦è°ƒç”¨çš„ Agent åç§°

=========================
ã€ä»»åŠ¡ 2ï¼šç”Ÿæˆå›å¤ã€‘
=========================
âš ï¸ã€å…³é”®æ¡ä»¶è§„åˆ™ã€‘âš ï¸

- ä»…å½“ intent == "direct_response" æ—¶ï¼š
  - æ‰å…è®¸åœ¨ direct_reply ä¸­ç”Ÿæˆå›å¤æ–‡æœ¬
  - emotion / emotion_description æ‰å…è®¸å¡«å†™

- å½“ intent != "direct_response" æ—¶ï¼š
  - direct_reply å¿…é¡»ä¸º ""
  - emotion å¿…é¡»ä¸º null
  - emotion_description å¿…é¡»ä¸º null

å›å¤ç”Ÿæˆè§„åˆ™ï¼š
- å›å¤å†…å®¹ä¸­ã€ä¸è¦ã€‘åŒ…å«æƒ…ç»ªè¯´æ˜æˆ–è¯­æ°”æè¿°
- å›å¤å¿…é¡»æ˜¯çº¯æ–‡æœ¬
- ä¸è¦å‡ºç°è¡¨æƒ…ç¬¦å·è§£é‡Šã€æƒ…ç»ªæ ‡ç­¾æˆ–æ‹¬å·è¯´æ˜

å¤šæ¶ˆæ¯è§„åˆ™ï¼š
- å¦‚éœ€æ‹†åˆ†ä¸ºå¤šæ¡æ¶ˆæ¯ï¼Œç”¨ [MSG_SPLIT] åˆ†éš”
- æœ€å¤šæ‹†åˆ†ä¸º 3 æ¡
- ä»…åœ¨è‡ªç„¶éœ€è¦æ—¶æ‹†åˆ†

å¯ç”¨ç³»ç»Ÿé£æ ¼çº¦æŸï¼š
{system_prompt}

=========================
ã€ä»»åŠ¡ 3ï¼šå¯¹è¯æ‘˜è¦ç”Ÿæˆã€‘
=========================
åŸºäºã€å®Œæ•´å¯¹è¯å†å² + å½“å‰æ¶ˆæ¯ã€‘ç”Ÿæˆä¸€ä¸ªâ€œç´¯ç§¯æ‘˜è¦â€ã€‚

æ‘˜è¦è¦æ±‚ï¼š
- æè¿°çš„æ˜¯â€œåˆ°ç›®å‰ä¸ºæ­¢çš„æ•´ä½“å¯¹è¯â€
- ä¸ä»…æ˜¯å½“å‰è¿™ä¸€è½®
- summary_text æ§åˆ¶åœ¨ 100 å­—ä»¥å†…

éœ€æå–çš„å…³é”®è¦ç´ ï¼š
- æ—¶é—´ï¼ˆå¦‚ï¼šä»Šå¤©ã€æ˜¨å¤©ã€å…·ä½“æ—¥æœŸï¼‰
- åœ°ç‚¹
- äººç‰©
- äº‹ä»¶
- ç”¨æˆ·æƒ…ç»ª

åŒæ—¶ç»™å‡ºï¼š
- topicsï¼šå¯¹è¯æ ¸å¿ƒè¯é¢˜
- user_stateï¼šç”¨æˆ·å½“å‰çŠ¶æ€çš„å®¢è§‚æè¿°

=========================
ã€ä»»åŠ¡ 4ï¼šè®°å¿†åˆ†æã€‘
=========================
åˆ¤æ–­æ˜¯å¦å­˜åœ¨â€œå€¼å¾—é•¿æœŸè®°å¿†â€çš„ä¿¡æ¯ã€‚

ä¸éœ€è¦è®°å¿†çš„æƒ…å†µï¼š
- æ—¥å¸¸å¯’æš„
- å·²åœ¨å†å²ä¸­å®Œæ•´é‡å¤çš„ä¿¡æ¯

éœ€è¦è®°å¿†çš„æƒ…å†µç¤ºä¾‹ï¼š
- ç”¨æˆ·åå¥½
- é•¿æœŸç›®æ ‡
- é‡è¦æƒ…ç»ªçŠ¶æ€
- é‡è¦ç”Ÿæ´»äº‹ä»¶

è‹¥ is_important ä¸º falseï¼š
- å…¶ä½™ memory å­—æ®µå…¨éƒ¨è®¾ä¸º null æˆ–ç©ºæ•°ç»„

=========================
ã€å½“å‰æ—¶é—´ã€‘
=========================
{current_time}

=========================
ã€å¼ºåˆ¶ JSON è¾“å‡ºæ ¼å¼ã€‘
=========================

ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

```json
    {{
    "intent": "direct_response" | "single_agent" | "multi_agent",
    "agents": [],
    "reasoning": "åˆ¤æ–­ç†ç”±",
    
    "conversation_summary": {{
        "summary_text": "ç»¼åˆæ•´ä¸ªå¯¹è¯çš„æ‘˜è¦æ–‡æœ¬ï¼ˆ100å­—ä»¥å†…ï¼‰",
        "key_elements": {{
            "time": ["æ—¶é—´ç‚¹1", "æ—¶é—´ç‚¹2"],
            "place": ["åœ°ç‚¹1", "åœ°ç‚¹2"],
            "people": ["äººç‰©1", "äººç‰©2"],
            "events": ["äº‹ä»¶1", "äº‹ä»¶2"],
            "emotions": ["æƒ…ç»ª1", "æƒ…ç»ª2"]
        }},
        "topics": ["è¯é¢˜1", "è¯é¢˜2", "è¯é¢˜3"],
        "user_state": "ç”¨æˆ·å½“å‰çŠ¶æ€æè¿°"
    }},
    
    "direct_reply": "çº¯æ–‡æœ¬å›å¤å†…å®¹ï¼ŒæŒ‰ç…§ä¸Šé¢å›å¤å†…å®¹æ ¼å¼è¯´æ˜è¿›è¡Œ",
    "emotion": "happy" | "gentle" | "sad" | "excited" | "angry" | "crying" | null,
    "emotion_description": "è¯¦ç»†çš„è¯­æ°”æè¿°ï¼Œå¦‚ï¼šå¼€å¿ƒã€è½»å¿«ï¼Œè¯­é€Ÿç¨å¿«ï¼Œè¯­è°ƒä¸Šæ‰¬" | null,
    "memory": {{
        "is_important": false,
        "importance_level": "low" | "medium" | "high" | null,
        "event_type": "preference" | "birthday" | "goal" | "emotion" | "life_event" | null,
        "event_summary": "äº‹ä»¶æ‘˜è¦" | null,
        "keywords": [],
        "event_date": "YYYY-MM-DD" | null,
        "raw_date_expression": "åŸå§‹æ—¶é—´è¡¨è¾¾" | null
    }}
}}
```
"""
    def __init__(
        self,
        agents: List[BaseAgent],
        llm_provider=None,
        enable_skills: bool = True,
        skill_threshold: int = 3,  # è¶…è¿‡æ­¤æ•°é‡çš„å¯é€‰Agentæ—¶ä½¿ç”¨æŠ€èƒ½é€‰æ‹©
        enable_unified_mode: bool = True
    ):
        """
        åˆå§‹åŒ–ç¼–æ’å™¨
        
        Args:
            agents: å¯ç”¨çš„Agentåˆ—è¡¨
            llm_provider: LLMæä¾›è€…å®ä¾‹ï¼ˆç”¨äºæ„å›¾è¯†åˆ«å’Œæœ€ç»ˆå†³ç­–ï¼‰
            enable_skills: æ˜¯å¦å¯ç”¨æŠ€èƒ½é€‰æ‹©æ¨¡å¼ï¼ˆç”ŸæˆTelegramæŒ‰é’®ï¼‰
            skill_threshold: è§¦å‘æŠ€èƒ½é€‰æ‹©çš„Agentæ•°é‡é˜ˆå€¼
        """
        self.agents = {agent.name: agent for agent in agents}
        self.llm_provider = llm_provider
        self.enable_skills = enable_skills
        self.skill_threshold = skill_threshold
        self.enable_unified_mode = enable_unified_mode

        # æ„å»ºAgentèƒ½åŠ›æè¿°
        self._capabilities = self._build_capabilities()
        
        # åˆ›å»ºå†…éƒ¨Routerç”¨äºåŸºäºç½®ä¿¡åº¦çš„Agenté€‰æ‹©
        self._router = Router(agents, RouterConfig(
            min_confidence=0.3,
            max_agents=5,
            enable_parallel=True
        ))
        
        logger.info(f"AgentOrchestratoråˆå§‹åŒ–å®Œæˆï¼ŒåŠ è½½äº†{len(self.agents)}ä¸ªAgent")

    # ç»Ÿä¸€åˆ†æ
    async def analyze_intent_unified(
            self,
            message: Message,
            context: ChatContext
    ) -> Tuple[IntentType, List[str], Dict[str, Any], IntentSource, Optional[str], Optional[MemoryAnalysis]]:
        """
        ç»Ÿä¸€åˆ†æï¼šä¸€æ¬¡ LLM è°ƒç”¨å®Œæˆæ„å›¾è¯†åˆ« + å›å¤ç”Ÿæˆ + è®°å¿†åˆ†æ
        """
        selected_by_confidence = self._router.select_agents(message, context)

        if not self.llm_provider:
            if not selected_by_confidence:
                return IntentType.DIRECT_RESPONSE, [], {}, IntentSource.RULE_BASED, None, None
            elif len(selected_by_confidence) == 1:
                return IntentType.SINGLE_AGENT, [
                    selected_by_confidence[0][0].name], {}, IntentSource.RULE_BASED, None, None
            else:
                return IntentType.MULTI_AGENT, [a.name for a, _ in
                                                selected_by_confidence], {}, IntentSource.RULE_BASED, None, None

        try:
            # ========== æ„å»ºå®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨ ==========
            messages = []
            
            # 1. æ„å»ºå¢å¼ºçš„ System Prompt
            # åŒ…å«ï¼šBotäººè®¾ + ç”¨æˆ·è®°å¿† + å¯¹è¯ç­–ç•¥ + UNIFIED_PROMPT_TEMPLATEä»»åŠ¡è¦æ±‚ + è¿”å›æ ¼å¼
            base_system_prompt = context.system_prompt if context and context.system_prompt else ""
            
            # å°† UNIFIED_PROMPT_TEMPLATE æ•´åˆåˆ° System Prompt ä¸­
            unified_task_prompt = self.UNIFIED_PROMPT_TEMPLATE.format(
                agent_capabilities=self._get_capabilities_prompt(),
                system_prompt="ï¼ˆå‚è§ä¸Šæ–¹çš„äººè®¾è®¾å®šï¼‰",
                current_time=datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M"),
            )
            # ç»„åˆå®Œæ•´çš„ System Prompt
            # base_system_prompt å·²åŒ…å«ï¼šäººè®¾ + è®°å¿† + ç­–ç•¥ + å¯¹è¯å†å²æç¤º
            # unified_task_prompt åŒ…å«ï¼šä»»åŠ¡è¦æ±‚ + è¿”å›æ ¼å¼
            enhanced_system_prompt = f"""{base_system_prompt}
=========================
ğŸ“‹ ä»»åŠ¡æŒ‡ä»¤
=========================
{unified_task_prompt}"""
            print("111111111")
            print(enhanced_system_prompt)
            messages.append({
                "role": "system",
                "content": enhanced_system_prompt
            })

            # 2. çŸ­æœŸå¯¹è¯å†å²ï¼ˆæœ€è¿‘ 5 è½®ï¼Œå³ 10 æ¡æ¶ˆæ¯ï¼‰
            if context and context.conversation_history:
                recent_history = context.conversation_history[-10:]  # æœ€å¤š10æ¡ï¼ˆ5è½®å¯¹è¯ï¼‰
                for hist_msg in recent_history:
                    if hasattr(hist_msg, 'content') and hasattr(hist_msg, 'user_id'):
                        # åˆ¤æ–­æ˜¯ç”¨æˆ·è¿˜æ˜¯åŠ©æ‰‹
                        user_id_str = str(hist_msg.user_id).lower()
                        if "agent" in user_id_str or "bot" in user_id_str or "assistant" in user_id_str:
                            role = "assistant"
                        else:
                            role = "user"
                        messages.append({
                            "role": role,
                            "content": hist_msg.content
                        })
                    elif isinstance(hist_msg, dict):
                        # å¦‚æœå·²ç»æ˜¯ dict æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                        messages.append(hist_msg)
            
            # 3. å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼ˆçº¯ç”¨æˆ·æ¶ˆæ¯ï¼Œä»»åŠ¡æŒ‡ä»¤å·²åœ¨ system prompt ä¸­ï¼‰
            messages.append({
                "role": "user",
                "content": message.content
            })
            
            # æ·»åŠ æ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯•
            logger.info(f"ğŸ“¨ [Orchestrator] Sending {len(messages)} messages to LLM")
            logger.debug(f"ğŸ“¨ [Orchestrator] Message roles: {[m['role'] for m in messages]}")
            
            # è°ƒç”¨ LLMï¼ˆä½¿ç”¨å®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨ï¼‰
            response = await self.llm_provider.generate_response(
                messages,  # â† å®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œä¸æ˜¯åªæœ‰ä¸€æ¡
                context=None  # context å·²ç»åœ¨ system prompt ä¸­
            )

            # éªŒè¯å“åº”ä¸ä¸ºç©º
            if not response:
                logger.error(f"âŒ [Orchestrator] LLM returned empty response! Messages count: {len(messages)}")
                logger.debug(f"ğŸ“ [Orchestrator] Last message content preview: {messages[-1].get('content', '')[:200]}...")
                raise ValueError("LLM returned empty response")
            
            # è§£æ JSON
            response_text = response.strip()
            
            # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©ºå­—ç¬¦ä¸²
            if not response_text:
                logger.error(f"âŒ [Orchestrator] LLM response is empty after strip! Original response: {repr(response)}")
                raise ValueError("LLM response is empty after processing")
            
            logger.debug(f"ğŸ“¤ [Orchestrator] Raw LLM response (first 500 chars): {response_text[:500]}...")
            
            # å°è¯•å¤šç§æ–¹å¼æå–JSON
            json_text = None
            
            # æ–¹å¼1: ä» ```json ä»£ç å—æå–
            if "```json" in response_text:
                json_text = response_text.split("```json")[1].split("```")[0].strip()
            # æ–¹å¼2: ä» ``` ä»£ç å—æå–
            elif "```" in response_text:
                json_text = response_text.split("```")[1].split("```")[0].strip()
            # æ–¹å¼3: æŸ¥æ‰¾JSONå¯¹è±¡ï¼ˆä½¿ç”¨æ‹¬å·åŒ¹é…è€Œéæ­£åˆ™ï¼‰
            else:
                # å°è¯•æ‰¾åˆ°å¹³è¡¡çš„ {} æ‹¬å·å¯¹
                start_idx = response_text.find('{')
                if start_idx != -1:
                    depth = 0
                    end_idx = start_idx
                    for i, char in enumerate(response_text[start_idx:], start_idx):
                        if char == '{':
                            depth += 1
                        elif char == '}':
                            depth -= 1
                            if depth == 0:
                                end_idx = i
                                break
                    if depth == 0:
                        json_text = response_text[start_idx:end_idx + 1].strip()
            
            # å¦‚æœä»æœªæ‰¾åˆ°ï¼Œå°è¯•ç›´æ¥è§£æï¼ˆå¯èƒ½å“åº”æœ¬èº«å°±æ˜¯JSONï¼‰
            if not json_text:
                json_text = response_text.strip()
            
            # éªŒè¯æå–åçš„JSONä¸ä¸ºç©º
            if not json_text:
                logger.error(f"âŒ [Orchestrator] Extracted JSON content is empty! Full response: {response[:500]}...")
                raise ValueError("Extracted JSON content is empty")

            try:
                data = json.loads(json_text)
            except json.JSONDecodeError as je:
                logger.error(f"âŒ [Orchestrator] JSON parse error: {je}")
                logger.error(f"ğŸ“ [Orchestrator] Failed JSON text: {json_text[:500]}...")
                raise

            intent = IntentType(data.get("intent", "direct_response"))
            agents = [a for a in data.get("agents", []) if a in self.agents]
            metadata = {"reasoning": data.get("reasoning", "")}
            direct_reply = data.get("direct_reply")

            # æå–æƒ…æ„Ÿæ ‡ç­¾å¹¶æ·»åŠ DEBUGæ—¥å¿—
            emotion = data.get("emotion")
            emotion_description = None
            if emotion and emotion in self.SUPPORTED_EMOTIONS:
                emotion_description = data.get("emotion_description")
                logger.debug(f"ğŸ­ [EMOTION EXTRACT] Extracted emotion from LLM response: emotion={emotion}, emotion_description={emotion_description}")
                metadata["emotion"] = emotion
                if emotion_description:
                    metadata["emotion_description"] = emotion_description
            else:
                logger.debug(f"ğŸ­ [EMOTION EXTRACT] No valid emotion extracted from LLM response: raw_emotion={emotion}")

            memory_data = data.get("memory", {})
            memory_analysis = MemoryAnalysis(
                is_important=memory_data.get("is_important", False),
                importance_level=memory_data.get("importance_level"),
                event_type=memory_data.get("event_type"),
                event_summary=memory_data.get("event_summary"),
                keywords=memory_data.get("keywords", []),
                event_date=memory_data.get("event_date"),
                raw_date_expression=memory_data.get("raw_date_expression"),
            )

            # è§£æå¯¹è¯æ‘˜è¦
            conversation_summary = data.get("conversation_summary")
            if conversation_summary:
                # éªŒè¯æ‘˜è¦ç»“æ„
                if isinstance(conversation_summary, dict):
                    required_fields = ['summary_text', 'key_elements', 'topics', 'user_state']
                    if all(field in conversation_summary for field in required_fields):
                        metadata["conversation_summary"] = conversation_summary
                        logger.debug(f"ğŸ“ [SUMMARY] Generated summary: {conversation_summary.get('summary_text', '')[:50]}...")
                    else:
                        logger.warning(f"ğŸ“ [SUMMARY] Incomplete summary structure, missing fields: {[f for f in required_fields if f not in conversation_summary]}")
                else:
                    logger.warning(f"ğŸ“ [SUMMARY] Invalid summary type: {type(conversation_summary)}")

            logger.info(f"ğŸ“Œ ç»Ÿä¸€æ¨¡å¼ | intent={intent} | is_important={memory_analysis.is_important} | emotion={emotion}" + (f" | emotion_description={emotion_description}" if emotion_description else ""))
            return intent, agents, metadata, IntentSource.LLM_UNIFIED, direct_reply, memory_analysis

        except Exception as e:
            import traceback
            logger.error(f"âŒ ç»Ÿä¸€åˆ†æå‡ºé”™: {e}")
            logger.error(f"ğŸ“ é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.debug(f"ğŸ“ å®Œæ•´å †æ ˆ: {traceback.format_exc()}")
            logger.info(f"âš ï¸ å›é€€åˆ°è§„åˆ™æ¨¡å¼ï¼Œselected_by_confidence has {len(selected_by_confidence) if selected_by_confidence else 0} agents")
            if selected_by_confidence:
                return IntentType.SINGLE_AGENT, [
                    selected_by_confidence[0][0].name], {}, IntentSource.FALLBACK, None, None
            return IntentType.DIRECT_RESPONSE, [], {}, IntentSource.FALLBACK, None, None

    def _build_capabilities(self) -> List[AgentCapability]:
        """æ„å»ºæ‰€æœ‰Agentçš„èƒ½åŠ›æè¿°åˆ—è¡¨"""
        capabilities = []
        for name, agent in self.agents.items():
            cap = AgentCapability(
                name=name,
                description=agent.description,
                keywords=getattr(agent, '_emotional_keywords', []) or 
                         getattr(agent, '_tech_keywords', []) or 
                         getattr(agent, '_tool_keywords', []),
                is_tool=name.lower().endswith('agent') and 'tool' in name.lower()
            )
            capabilities.append(cap)
        return capabilities
    
    def _get_capabilities_prompt(self) -> str:
        """ç”ŸæˆAgentèƒ½åŠ›æè¿°çš„æç¤ºè¯"""
        cap_list = []
        for cap in self._capabilities:
            cap_type = "å·¥å…·" if cap.is_tool else "Agent"
            cap_list.append(f"- {cap.name} ({cap_type}): {cap.description}")
        return "\n".join(cap_list)
    
    async def analyze_intent(
        self,
        message: Message,
        context: ChatContext
    ) -> Tuple[IntentType, List[str], Dict[str, Any], IntentSource]:
        """
        åˆ†æç”¨æˆ·æ¶ˆæ¯çš„æ„å›¾
        
        ä½¿ç”¨LLMåˆ†ææ¶ˆæ¯å†…å®¹ï¼Œåˆ¤æ–­éœ€è¦è°ƒç”¨å“ªäº›Agentã€‚
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            
        Returns:
            Tuple[IntentType, List[str], Dict, IntentSource]: 
                (æ„å›¾ç±»å‹, é€‰ä¸­çš„Agentåç§°åˆ—è¡¨, å…ƒæ•°æ®, æ„å›¾è¯†åˆ«æ¥æº)
        """
        # é¦–å…ˆä½¿ç”¨Routerçš„åŸºäºè§„åˆ™çš„ç½®ä¿¡åº¦è¯„ä¼°
        selected_by_confidence = self._router.select_agents(message, context)
        
        # å¦‚æœæ²¡æœ‰LLMæä¾›è€…ï¼Œç›´æ¥ä½¿ç”¨åŸºäºè§„åˆ™çš„ç»“æœ
        if not self.llm_provider:
            logger.info("ğŸ“Œ æ„å›¾è¯†åˆ«æ¥æº: åŸºäºè§„åˆ™ (æ— LLMæä¾›è€…)")
            if not selected_by_confidence:
                return IntentType.DIRECT_RESPONSE, [], {}, IntentSource.RULE_BASED
            elif len(selected_by_confidence) == 1:
                return IntentType.SINGLE_AGENT, [selected_by_confidence[0][0].name], {}, IntentSource.RULE_BASED
            else:
                agent_names = [agent.name for agent, _ in selected_by_confidence]
                return IntentType.MULTI_AGENT, agent_names, {}, IntentSource.RULE_BASED
        
        # ä½¿ç”¨LLMè¿›è¡Œæ›´ç²¾ç¡®çš„æ„å›¾è¯†åˆ«
        try:
            intent_prompt = f"""åˆ†æä»¥ä¸‹ç”¨æˆ·æ¶ˆæ¯ï¼Œåˆ¤æ–­åº”è¯¥å¦‚ä½•å¤„ç†ã€‚

å¯ç”¨çš„Agentèƒ½åŠ›:
{self._get_capabilities_prompt()}

ç”¨æˆ·æ¶ˆæ¯: {message.content}

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µ:
- intent: "direct_response" | "single_agent" | "multi_agent" | "tool_call"
- agents: [é€‰ä¸­çš„Agentåç§°åˆ—è¡¨]
- reasoning: é€‰æ‹©åŸå› 

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

            response = await self.llm_provider.generate_response(
                [{"role": "user", "content": intent_prompt}],
                context="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è·¯ç”±åŠ©æ‰‹ï¼Œè´Ÿè´£åˆ†æç”¨æˆ·æ„å›¾å¹¶é€‰æ‹©åˆé€‚çš„å¤„ç†æ–¹å¼ã€‚"
            )
            
            # è§£æLLMå“åº”
            try:
                # å°è¯•æå–JSON
                response_text = response.strip()
                if response_text.startswith("```"):
                    response_text = response_text.split("```")[1]
                    if response_text.startswith("json"):
                        response_text = response_text[4:]
                
                result = json.loads(response_text)
                intent = IntentType(result.get("intent", "direct_response"))
                agents = result.get("agents", [])
                metadata = {"reasoning": result.get("reasoning", "")}
                
                # éªŒè¯Agentåç§°
                valid_agents = [a for a in agents if a in self.agents]
                
                logger.info("ğŸ“Œ æ„å›¾è¯†åˆ«æ¥æº: åŸºäºLLMæ¨ç†")
                return intent, valid_agents, metadata, IntentSource.LLM_BASED
                
            except (json.JSONDecodeError, ValueError) as e:
                logger.warning(f"è§£æLLMæ„å›¾å“åº”å¤±è´¥: {e}")
                logger.info("ğŸ“Œ æ„å›¾è¯†åˆ«æ¥æº: å›é€€åˆ°è§„åˆ™ (LLMè§£æå¤±è´¥)")
                # å›é€€åˆ°åŸºäºè§„åˆ™çš„ç»“æœ
                if selected_by_confidence:
                    agent_names = [agent.name for agent, _ in selected_by_confidence]
                    intent = IntentType.SINGLE_AGENT if len(agent_names) == 1 else IntentType.MULTI_AGENT
                    return intent, agent_names, {}, IntentSource.FALLBACK
                return IntentType.DIRECT_RESPONSE, [], {}, IntentSource.FALLBACK
                
        except Exception as e:
            logger.error(f"LLMæ„å›¾åˆ†æå‡ºé”™: {e}")
            logger.info("ğŸ“Œ æ„å›¾è¯†åˆ«æ¥æº: å›é€€åˆ°è§„åˆ™ (LLMè°ƒç”¨å¤±è´¥)")
            # å›é€€åˆ°åŸºäºè§„åˆ™çš„ç»“æœ
            if selected_by_confidence:
                agent_names = [agent.name for agent, _ in selected_by_confidence]
                intent = IntentType.SINGLE_AGENT if len(agent_names) == 1 else IntentType.MULTI_AGENT
                return intent, agent_names, {}, IntentSource.FALLBACK
            return IntentType.DIRECT_RESPONSE, [], {}, IntentSource.FALLBACK
    
    def generate_skill_options(
        self,
        message: Message,
        context: ChatContext
    ) -> List[Dict[str, str]]:
        """
        ç”ŸæˆæŠ€èƒ½é€‰é¡¹ä¾›ç”¨æˆ·é€‰æ‹©
        
        å½“æœ‰å¤šä¸ªå¯èƒ½çš„Agentæ—¶ï¼Œç”ŸæˆTelegramæŒ‰é’®é€‰é¡¹ï¼Œ
        è®©ç”¨æˆ·ä¸»åŠ¨é€‰æ‹©ï¼Œä»¥èŠ‚çœtokenæ¶ˆè€—ã€‚
        
        Returns:
            List[Dict]: åŒ…å«button_textå’Œcallback_dataçš„é€‰é¡¹åˆ—è¡¨
        """
        options = []
        selected = self._router.select_agents(message, context)
        
        for agent, confidence in selected[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ªé€‰é¡¹
            options.append({
                "button_text": f"{agent.name}",
                "callback_data": f"skill:{agent.name}",
                "description": agent.description[:50] + "..." if len(agent.description) > 50 else agent.description,
                "confidence": confidence
            })
        
        return options
    
    async def execute_agents(
        self,
        message: Message,
        context: ChatContext,
        agent_names: List[str]
    ) -> List[AgentResponse]:
        """
        æ‰§è¡ŒæŒ‡å®šçš„Agentå¹¶æ”¶é›†å“åº”
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            agent_names: è¦æ‰§è¡Œçš„Agentåç§°åˆ—è¡¨
            
        Returns:
            List[AgentResponse]: Agentå“åº”åˆ—è¡¨
        """
        responses = []
        
        for agent_name in agent_names:
            if agent_name not in self.agents:
                logger.warning(f"Agentæœªæ‰¾åˆ°: {agent_name}")
                continue
            
            agent = self.agents[agent_name]
            try:
                response = agent.respond(message, context)
                responses.append(response)
                logger.info(f"Agent {agent_name} å“åº”æˆåŠŸ")
            except Exception as e:
                logger.error(f"Agent {agent_name} æ‰§è¡Œå¤±è´¥: {e}")
        
        return responses
    
    async def synthesize_response(
        self,
        message: Message,
        agent_responses: List[AgentResponse],
        context: ChatContext
    ) -> str:
        """
        ç»¼åˆå¤šä¸ªAgentçš„å“åº”ç”Ÿæˆæœ€ç»ˆå›å¤
        
        ä½¿ç”¨LLMæ•´åˆæ‰€æœ‰Agentçš„è¾“å‡ºï¼Œç”Ÿæˆç»Ÿä¸€è¿è´¯çš„å›å¤ã€‚
        
        Args:
            message: åŸå§‹ç”¨æˆ·æ¶ˆæ¯
            agent_responses: å„Agentçš„å“åº”
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            
        Returns:
            str: æœ€ç»ˆç»¼åˆå›å¤
        """
        if not agent_responses:
            return "æŠ±æ­‰ï¼Œæˆ‘ç›®å‰æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚è¯·ç¨åå†è¯•ã€‚"
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªå“åº”ï¼Œç›´æ¥è¿”å›
        if len(agent_responses) == 1:
            return agent_responses[0].content
        
        # å¦‚æœæ²¡æœ‰LLMæä¾›è€…ï¼Œç®€å•æ‹¼æ¥å“åº”
        if not self.llm_provider:
            combined = []
            for resp in agent_responses:
                combined.append(f"ã€{resp.agent_name}ã€‘\n{resp.content}")
            return "\n\n".join(combined)
        
        # ä½¿ç”¨LLMç»¼åˆå¤šä¸ªå“åº”
        try:
            responses_text = ""
            for resp in agent_responses:
                responses_text += f"\n[{resp.agent_name}çš„åˆ†æ]:\n{resp.content}\n"
            
            synthesis_prompt = f"""ç”¨æˆ·é—®é¢˜: {message.content}

å„ä¸“å®¶çš„åˆ†æç»“æœ:
{responses_text}

è¯·ç»¼åˆä»¥ä¸Šå„ä¸“å®¶çš„åˆ†æï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´ã€è¿è´¯çš„å›å¤ç»™ç”¨æˆ·ã€‚
è¦æ±‚ï¼š
1. æ•´åˆå„ä¸“å®¶çš„è§‚ç‚¹
2. ä¿æŒè¯­æ°”ä¸€è‡´å’Œè‡ªç„¶
3. ä¸è¦æåŠ"ä¸“å®¶"æˆ–"åˆ†æç»“æœ"
4. ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜
5. å›å¤å†…å®¹ä¸­ä¸è¦åŒ…å«è¯­æ°”æ ‡æ³¨ï¼Œç›´æ¥è¾“å‡ºçº¯æ–‡æœ¬å›å¤"""

            final_response = await self.llm_provider.generate_response(
                [{"role": "user", "content": synthesis_prompt}],
                context="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œè´Ÿè´£æ•´åˆå¤šä¸ªä¸“å®¶çš„æ„è§ç»™ç”¨æˆ·æä¾›å®Œæ•´çš„å›ç­”ã€‚"
            )
            
            return final_response
            
        except Exception as e:
            logger.error(f"ç»¼åˆå“åº”ç”Ÿæˆå¤±è´¥: {e}")
            # å›é€€åˆ°ç®€å•æ‹¼æ¥
            return agent_responses[0].content

    async def process(
            self,
            message: Message,
            context: ChatContext,
            force_skill_selection: bool = False
    ) -> OrchestratorResult:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯çš„ä¸»å…¥å£"""
        result = OrchestratorResult(intent_type=IntentType.DIRECT_RESPONSE)

        # æ ¹æ®é…ç½®é€‰æ‹©å¤„ç†æ¨¡å¼
        if self.enable_unified_mode and self.llm_provider:
            # ğŸ”‘ ç»Ÿä¸€æ¨¡å¼
            intent_type, agent_names, metadata, intent_source, direct_reply, memory_analysis = \
                await self.analyze_intent_unified(message, context)

            result.intent_type = intent_type
            result.intent_source = intent_source
            result.selected_agents = agent_names
            result.metadata = metadata
            result.metadata["intent_source"] = intent_source.value
            result.memory_analysis = memory_analysis
        else:
            # åŸæœ‰æ¨¡å¼
            intent_type, agent_names, metadata, intent_source = await self.analyze_intent(message, context)
            result.intent_type = intent_type
            result.intent_source = intent_source
            result.selected_agents = agent_names
            result.metadata = metadata
            result.metadata["intent_source"] = intent_source.value
            direct_reply = None

        logger.info(f"ğŸ¯ Intent type: {result.intent_type} | Source: {result.intent_source}")

        # æŠ€èƒ½é€‰æ‹©æ£€æŸ¥
        if self.enable_skills and (force_skill_selection or len(result.selected_agents) >= self.skill_threshold):
            skill_options = self.generate_skill_options(message, context)
            if skill_options:
                result.intent_type = IntentType.SKILL_SELECTION
                result.skill_options = skill_options
                result.final_response = "è¯·é€‰æ‹©æ‚¨éœ€è¦çš„æœåŠ¡ï¼š"
                return result

        # ç›´æ¥å“åº”
        if result.intent_type == IntentType.DIRECT_RESPONSE or not result.selected_agents:
            if direct_reply:
                result.final_response = direct_reply
            elif self.llm_provider:
                try:
                    messages = []
                    if context and context.system_prompt:
                        messages.append({"role": "system", "content": context.system_prompt})
                    messages.append({"role": "user", "content": message.content})
                    result.final_response = await self.llm_provider.generate_response(messages, context=None)
                except Exception as e:
                    logger.error(f"ç›´æ¥å“åº”ç”Ÿæˆå¤±è´¥: {e}")
                    result.final_response = "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"
            else:
                result.final_response = "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"
            return result

        # Agent å¤„ç†
        agent_responses = await self.execute_agents(message, context, result.selected_agents)
        result.agent_responses = agent_responses
        result.final_response = await self.synthesize_response(message, agent_responses, context)

        return result

    async def process_skill_callback(
        self,
        skill_name: str,
        message: Message,
        context: ChatContext
    ) -> OrchestratorResult:
        """
        å¤„ç†ç”¨æˆ·çš„æŠ€èƒ½é€‰æ‹©å›è°ƒ
        
        å½“ç”¨æˆ·ç‚¹å‡»æŠ€èƒ½æŒ‰é’®åï¼Œæ‰§è¡Œç›¸åº”çš„Agentã€‚
        
        Args:
            skill_name: ç”¨æˆ·é€‰æ‹©çš„æŠ€èƒ½ï¼ˆAgentï¼‰åç§°
            message: åŸå§‹ç”¨æˆ·æ¶ˆæ¯
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            
        Returns:
            OrchestratorResult: å¤„ç†ç»“æœ
        """
        result = OrchestratorResult(
            intent_type=IntentType.SINGLE_AGENT,
            selected_agents=[skill_name]
        )
        
        if skill_name not in self.agents:
            result.final_response = f"æŠ±æ­‰ï¼ŒæŠ€èƒ½ '{skill_name}' ä¸å¯ç”¨ã€‚"
            return result
        
        # æ‰§è¡Œé€‰ä¸­çš„Agent
        agent_responses = await self.execute_agents(message, context, [skill_name])
        result.agent_responses = agent_responses
        
        if agent_responses:
            result.final_response = agent_responses[0].content
        else:
            result.final_response = "æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ã€‚"
        
        return result
    
    def add_agent(self, agent: BaseAgent) -> None:
        """åŠ¨æ€æ·»åŠ Agent"""
        self.agents[agent.name] = agent
        self._capabilities = self._build_capabilities()
        self._router.add_agent(agent)
        logger.info(f"æ·»åŠ Agent: {agent.name}")
    
    def remove_agent(self, agent_name: str) -> bool:
        """åŠ¨æ€ç§»é™¤Agent"""
        if agent_name in self.agents:
            del self.agents[agent_name]
            self._capabilities = self._build_capabilities()
            self._router.remove_agent(agent_name)
            logger.info(f"ç§»é™¤Agent: {agent_name}")
            return True
        return False
