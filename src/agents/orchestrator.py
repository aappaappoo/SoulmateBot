"""
LLM-Powered Agent Orchestrator

This module provides intelligent orchestration for the multi-agent system.
It uses LLM to automatically determine which agents/tools to invoke based on user requests,
and coordinates multiple agent responses into a final coherent reply.

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. è‡ªåŠ¨è¯†åˆ«ç”¨æˆ·æ„å›¾ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨Agentèƒ½åŠ›
2. æ”¯æŒè°ƒç”¨å¤šä¸ªAgentå¹¶åè°ƒç»“æœ
3. ä½¿ç”¨æœ€ç»ˆAgentç”Ÿæˆç»Ÿä¸€å›å¤
4. æ”¯æŒSkillsç³»ç»Ÿå‡å°‘tokenæ¶ˆè€—
"""
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import json
import asyncio
from loguru import logger

from .base_agent import BaseAgent
from .models import Message, ChatContext, AgentResponse
from .router import Router, RouterConfig


class IntentType(str, Enum):
    """ç”¨æˆ·æ„å›¾ç±»å‹"""
    DIRECT_RESPONSE = "direct_response"  # ç›´æ¥å›å¤ï¼Œæ— éœ€Agent
    SINGLE_AGENT = "single_agent"  # éœ€è¦å•ä¸ªAgentå¤„ç†
    MULTI_AGENT = "multi_agent"  # éœ€è¦å¤šä¸ªAgentåä½œ
    TOOL_CALL = "tool_call"  # éœ€è¦è°ƒç”¨å·¥å…·
    SKILL_SELECTION = "skill_selection"  # éœ€è¦ç”¨æˆ·é€‰æ‹©æŠ€èƒ½


@dataclass
class AgentCapability:
    """Agentèƒ½åŠ›æè¿°"""
    name: str
    description: str
    keywords: List[str] = field(default_factory=list)
    is_tool: bool = False


class IntentSource(str, Enum):
    """æ„å›¾è¯†åˆ«æ¥æº"""
    RULE_BASED = "rule_based"  # åŸºäºè§„åˆ™ï¼ˆå…³é”®è¯åŒ¹é…ã€ç½®ä¿¡åº¦è¯„åˆ†ï¼‰
    LLM_BASED = "llm_based"    # åŸºäºå¤§æ¨¡å‹æ¨ç†
    LLM_UNIFIED = "llm_unified" # åŸºäºå¤§æ¨¡å‹ç»Ÿä¸€æ¨ç†
    FALLBACK = "fallback"      # å›é€€æœºåˆ¶


@dataclass
class MemoryAnalysis:
    """è®°å¿†åˆ†æç»“æœï¼ˆç»Ÿä¸€æ¨¡å¼è¿”å›ï¼‰"""
    is_important: bool = False
    importance_level: Optional[str] = None
    event_type: Optional[str] = None
    event_summary: Optional[str] = None
    keywords: List[str] = field(default_factory=list)
    event_date: Optional[str] = None
    raw_date_expression: Optional[str] = None

@dataclass
class OrchestratorResult:
    """ç¼–æ’å™¨å¤„ç†ç»“æœ"""
    intent_type: IntentType
    intent_source: IntentSource = IntentSource.RULE_BASED  # æ„å›¾è¯†åˆ«æ¥æº
    selected_agents: List[str] = field(default_factory=list)
    agent_responses: List[AgentResponse] = field(default_factory=list)
    final_response: str = ""
    metadata: Dict[str, Any] = field(default_factory=dict)
    skill_options: List[Dict[str, str]] = field(default_factory=list)
    memory_analysis: Optional[MemoryAnalysis] = None


class AgentOrchestrator:
    """
    æ™ºèƒ½Agentç¼–æ’å™¨
    
    ä½¿ç”¨LLMè‡ªåŠ¨åˆ†æç”¨æˆ·è¯·æ±‚ï¼Œå†³å®šè°ƒç”¨å“ªäº›Agentï¼Œ
    å¹¶åè°ƒå¤šä¸ªAgentçš„è¾“å‡ºç”Ÿæˆæœ€ç»ˆå›å¤ã€‚
    
    å·¥ä½œæµç¨‹:
    1. åˆ†æç”¨æˆ·æ¶ˆæ¯ï¼Œè¯†åˆ«æ„å›¾
    2. æ ¹æ®æ„å›¾é€‰æ‹©åˆé€‚çš„Agent(s)
    3. è°ƒç”¨é€‰ä¸­çš„Agentè·å–å“åº”
    4. ä½¿ç”¨æœ€ç»ˆå†³ç­–Agentæ•´åˆæ‰€æœ‰å“åº”
    5. è¿”å›æœ€ç»ˆç»“æœç»™ç”¨æˆ·
    """
    # æ”¯æŒçš„æƒ…æ„Ÿæ ‡ç­¾
    SUPPORTED_EMOTIONS = ["happy", "gentle", "sad", "excited", "angry", "crying"]
    
    UNIFIED_PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œéœ€è¦åŒæ—¶å®Œæˆå››é¡¹ä»»åŠ¡ï¼š

    ## ä»»åŠ¡1ï¼šæ„å›¾è¯†åˆ«
    åˆ¤æ–­ç”¨æˆ·æ¶ˆæ¯åº”è¯¥å¦‚ä½•å¤„ç†ï¼š
    - "direct_response": æ—¥å¸¸é—²èŠã€é—®å€™ã€ç®€å•é—®ç­”ï¼Œç”±ä½ ç›´æ¥å›å¤
    - "single_agent": éœ€è¦å•ä¸ªä¸“ä¸šAgentå¤„ç†
    - "multi_agent": éœ€è¦å¤šä¸ªAgentåä½œå¤„ç†

    å¯ç”¨çš„Agentèƒ½åŠ›ï¼š
    {agent_capabilities}

    ## ä»»åŠ¡2ï¼šç”Ÿæˆå›å¤ï¼ˆä»…å½“ intent ä¸º direct_response æ—¶ï¼‰
    æ ¹æ®ä»¥ä¸‹äººè®¾ç›´æ¥å›å¤ç”¨æˆ·ï¼š
    {system_prompt}
    
    **é‡è¦ï¼šå›å¤å†…å®¹ï¼ˆdirect_replyï¼‰ä¸­ä¸è¦åŒ…å«è¯­æ°”æ ‡æ³¨ï¼Œç›´æ¥è¾“å‡ºçº¯æ–‡æœ¬å›å¤ã€‚æƒ…æ„Ÿä¿¡æ¯é€šè¿‡emotionå’Œemotion_descriptionå­—æ®µå•ç‹¬è¿”å›ã€‚**
    
    å¯ç”¨çš„æƒ…æ„Ÿæ ‡ç­¾åŠä½¿ç”¨åœºæ™¯ï¼š
    - happy: ç”¨äºè¡¨è¾¾é«˜å…´ã€æ„‰å¿«çš„æƒ…ç»ª
    - excited: ç”¨äºè¡¨è¾¾æ¿€åŠ¨ã€çƒ­æƒ…çš„æƒ…ç»ª
    - gentle: ç”¨äºè¡¨è¾¾æ¸©æš–ã€å…³æ€€çš„æƒ…ç»ª
    - sad: ç”¨äºè¡¨è¾¾æ‚²ä¼¤ã€å¤±è½çš„æƒ…ç»ª
    - angry: ç”¨äºè¡¨è¾¾æ„¤æ€’çš„æƒ…ç»ª
    - crying: ç”¨äºè¡¨è¾¾å§”å±ˆçš„æƒ…ç»ª
    
    æƒ…æ„Ÿæè¿°ç¤ºä¾‹ï¼ˆå¡«å…¥emotion_descriptionå­—æ®µï¼‰ï¼š
    - "å¼€å¿ƒã€è½»å¿«ï¼Œè¯­é€Ÿç¨å¿«ï¼Œè¯­è°ƒä¸Šæ‰¬"
    - "æ¸©æŸ”ã€è½»å£°ï¼Œè¯­è°ƒæŸ”å’Œ"
    - "å…´å¥‹ã€æ´»è·ƒï¼Œå¯Œæœ‰æ„ŸæŸ“åŠ›"

    ## ä»»åŠ¡3ï¼šå¯¹è¯æ‘˜è¦ç”Ÿæˆï¼ˆé‡è¦ï¼ï¼‰
    è¯·æ ¹æ®ã€å¯¹è¯å†å²ã€‘å’Œå½“å‰æ¶ˆæ¯ï¼Œç”Ÿæˆä¸€ä¸ªç´¯ç§¯çš„å¯¹è¯æ‘˜è¦ã€‚
    
    æ‘˜è¦è¦æ±‚ï¼š
    1. **ç»¼åˆæ•´ä¸ªå¯¹è¯**ï¼Œä¸åªæ˜¯å½“å‰è¿™ä¸€è½®
    2. æå–å…³é”®è¦ç´ ï¼š
       - æ—¶é—´ï¼šå¯¹è¯ä¸­æåˆ°çš„æ—¶é—´ç‚¹ï¼ˆå¦‚"ä»Šå¤©"ã€"ä¸‹ç­å"ã€"æ˜¨å¤©"ç­‰ï¼‰
       - åœ°ç‚¹ï¼šæåˆ°çš„åœ°ç‚¹ï¼ˆå¦‚"å…¬å¸"ã€"å®¶é‡Œ"ã€"å­¦æ ¡"ç­‰ï¼‰
       - äººç‰©ï¼šæ¶‰åŠçš„äººç‰©ï¼ˆå¦‚"ç”¨æˆ·"ã€"é¢†å¯¼"ã€"æœ‹å‹"ã€"å®¶äºº"ç­‰ï¼‰
       - äº‹ä»¶ï¼šå‘ç”Ÿçš„äº‹æƒ…æˆ–è®¨è®ºçš„è¯é¢˜
       - æƒ…ç»ªï¼šç”¨æˆ·è¡¨è¾¾çš„æƒ…ç»ªçŠ¶æ€
    3. è®°å½•å¯¹è¯çš„æ ¸å¿ƒè¯é¢˜
    4. æè¿°ç”¨æˆ·å½“å‰çš„çŠ¶æ€
    
    è¿™ä¸ªæ‘˜è¦å°†ç”¨äºåç»­å¯¹è¯çš„ä¸Šä¸‹æ–‡ç†è§£ï¼Œè¯·ç¡®ä¿ä¿¡æ¯å®Œæ•´ä¸”å‡†ç¡®ã€‚

    ## ä»»åŠ¡4ï¼šè®°å¿†åˆ†æ
    åˆ¤æ–­å¯¹è¯æ˜¯å¦åŒ…å«å€¼å¾—è®°ä½çš„é‡è¦ä¿¡æ¯ï¼ˆä¸ªäººä¿¡æ¯ã€åå¥½ã€ç›®æ ‡ã€é‡è¦äº‹ä»¶ç­‰ï¼‰ã€‚
    æ—¥å¸¸å¯’æš„ï¼ˆä½ å¥½ã€è°¢è°¢ç­‰ï¼‰ä¸é‡è¦ã€‚

    å½“å‰æ—¶é—´ï¼š{current_time}
    ç”¨æˆ·æ¶ˆæ¯ï¼š{user_message}

    è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼š
    ```json
    {{
        "intent": "direct_response" | "single_agent" | "multi_agent",
        "agents": [],
        "reasoning": "åˆ¤æ–­ç†ç”±",
        
        "conversation_summary": {{
            "summary_text": "ç»¼åˆæ•´ä¸ªå¯¹è¯çš„æ‘˜è¦æ–‡æœ¬ï¼ˆ100å­—ä»¥å†…ï¼‰",
            "key_elements": {{
                "time": ["æ—¶é—´ç‚¹1", "æ—¶é—´ç‚¹2"],
                "place": ["åœ°ç‚¹1", "åœ°ç‚¹2"],
                "people": ["äººç‰©1", "äººç‰©2"],
                "events": ["äº‹ä»¶1", "äº‹ä»¶2"],
                "emotions": ["æƒ…ç»ª1", "æƒ…ç»ª2"]
            }},
            "topics": ["è¯é¢˜1", "è¯é¢˜2", "è¯é¢˜3"],
            "user_state": "ç”¨æˆ·å½“å‰çŠ¶æ€æè¿°"
        }},
        
        "direct_reply": "çº¯æ–‡æœ¬å›å¤å†…å®¹ï¼Œä¸åŒ…å«è¯­æ°”æ ‡æ³¨",
        "emotion": "happy" | "gentle" | "sad" | "excited" | "angry" | "crying" | null,
        "emotion_description": "è¯¦ç»†çš„è¯­æ°”æè¿°ï¼Œå¦‚ï¼šå¼€å¿ƒã€è½»å¿«ï¼Œè¯­é€Ÿç¨å¿«ï¼Œè¯­è°ƒä¸Šæ‰¬" | null,
        "memory": {{
            "is_important": false,
            "importance_level": "low" | "medium" | "high" | null,
            "event_type": "preference" | "birthday" | "goal" | "emotion" | "life_event" | null,
            "event_summary": "äº‹ä»¶æ‘˜è¦" | null,
            "keywords": [],
            "event_date": "YYYY-MM-DD" | null,
            "raw_date_expression": "åŸå§‹æ—¶é—´è¡¨è¾¾" | null
        }}
    }}
    ```"""
    def __init__(
        self,
        agents: List[BaseAgent],
        llm_provider=None,
        enable_skills: bool = True,
        skill_threshold: int = 3,  # è¶…è¿‡æ­¤æ•°é‡çš„å¯é€‰Agentæ—¶ä½¿ç”¨æŠ€èƒ½é€‰æ‹©
        enable_unified_mode: bool = True
    ):
        """
        åˆå§‹åŒ–ç¼–æ’å™¨
        
        Args:
            agents: å¯ç”¨çš„Agentåˆ—è¡¨
            llm_provider: LLMæä¾›è€…å®ä¾‹ï¼ˆç”¨äºæ„å›¾è¯†åˆ«å’Œæœ€ç»ˆå†³ç­–ï¼‰
            enable_skills: æ˜¯å¦å¯ç”¨æŠ€èƒ½é€‰æ‹©æ¨¡å¼ï¼ˆç”ŸæˆTelegramæŒ‰é’®ï¼‰
            skill_threshold: è§¦å‘æŠ€èƒ½é€‰æ‹©çš„Agentæ•°é‡é˜ˆå€¼
        """
        self.agents = {agent.name: agent for agent in agents}
        self.llm_provider = llm_provider
        self.enable_skills = enable_skills
        self.skill_threshold = skill_threshold
        self.enable_unified_mode = enable_unified_mode

        # æ„å»ºAgentèƒ½åŠ›æè¿°
        self._capabilities = self._build_capabilities()
        
        # åˆ›å»ºå†…éƒ¨Routerç”¨äºåŸºäºç½®ä¿¡åº¦çš„Agenté€‰æ‹©
        self._router = Router(agents, RouterConfig(
            min_confidence=0.3,
            max_agents=5,
            enable_parallel=True
        ))
        
        logger.info(f"AgentOrchestratoråˆå§‹åŒ–å®Œæˆï¼ŒåŠ è½½äº†{len(self.agents)}ä¸ªAgent")

    # ç»Ÿä¸€åˆ†æ
    async def analyze_intent_unified(
            self,
            message: Message,
            context: ChatContext
    ) -> Tuple[IntentType, List[str], Dict[str, Any], IntentSource, Optional[str], Optional[MemoryAnalysis]]:
        """
        ç»Ÿä¸€åˆ†æï¼šä¸€æ¬¡ LLM è°ƒç”¨å®Œæˆæ„å›¾è¯†åˆ« + å›å¤ç”Ÿæˆ + è®°å¿†åˆ†æ
        """
        selected_by_confidence = self._router.select_agents(message, context)

        if not self.llm_provider:
            if not selected_by_confidence:
                return IntentType.DIRECT_RESPONSE, [], {}, IntentSource.RULE_BASED, None, None
            elif len(selected_by_confidence) == 1:
                return IntentType.SINGLE_AGENT, [
                    selected_by_confidence[0][0].name], {}, IntentSource.RULE_BASED, None, None
            else:
                return IntentType.MULTI_AGENT, [a.name for a, _ in
                                                selected_by_confidence], {}, IntentSource.RULE_BASED, None, None

        try:
            # ========== ä¿®å¤ï¼šæ„å»ºå®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨ ==========
            messages = []
            
            # 1. System Promptï¼ˆå·²ç»åŒ…å«äººè®¾ + è®°å¿† + æ‘˜è¦ + ç­–ç•¥ï¼‰
            if context and context.system_prompt:
                messages.append({
                    "role": "system",
                    "content": context.system_prompt
                })

            # 2. çŸ­æœŸå¯¹è¯å†å²ï¼ˆæœ€è¿‘ 3-5 è½®ï¼Œå³ 6-10 æ¡æ¶ˆæ¯ï¼‰
            if context and context.conversation_history:
                recent_history = context.conversation_history[-10:]  # æœ€å¤š10æ¡
                for hist_msg in recent_history:
                    if hasattr(hist_msg, 'content') and hasattr(hist_msg, 'user_id'):
                        # åˆ¤æ–­æ˜¯ç”¨æˆ·è¿˜æ˜¯åŠ©æ‰‹
                        user_id_str = str(hist_msg.user_id).lower()
                        if "agent" in user_id_str or "bot" in user_id_str or "assistant" in user_id_str:
                            role = "assistant"
                        else:
                            role = "user"
                        messages.append({
                            "role": role,
                            "content": hist_msg.content
                        })
                    elif isinstance(hist_msg, dict):
                        # å¦‚æœå·²ç»æ˜¯ dict æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                        messages.append(hist_msg)
            
            # 3. å½“å‰ç”¨æˆ·æ¶ˆæ¯ + ç»Ÿä¸€ Prompt æ¨¡æ¿
            prompt = self.UNIFIED_PROMPT_TEMPLATE.format(
                agent_capabilities=self._get_capabilities_prompt(),
                system_prompt="",  # å·²ç»åœ¨ system æ¶ˆæ¯ä¸­äº†
                current_time=datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M"),
                user_message=message.content
            )
            messages.append({
                "role": "user",
                "content": prompt
            })
            
            # æ·»åŠ æ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯•
            logger.info(f"ğŸ“¨ [Orchestrator] Sending {len(messages)} messages to LLM")
            logger.debug(f"ğŸ“¨ [Orchestrator] Message roles: {[m['role'] for m in messages]}")
            
            # è°ƒç”¨ LLMï¼ˆä½¿ç”¨å®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨ï¼‰
            response = await self.llm_provider.generate_response(
                messages,  # â† å®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œä¸æ˜¯åªæœ‰ä¸€æ¡
                context=None  # context å·²ç»åœ¨ system prompt ä¸­
            )

            # è§£æ JSON
            response_text = response.strip()
            if "```json" in response_text:
                response_text = response_text.split("```json")[1].split("```")[0]
            elif "```" in response_text:
                response_text = response_text.split("```")[1].split("```")[0]

            data = json.loads(response_text.strip())

            intent = IntentType(data.get("intent", "direct_response"))
            agents = [a for a in data.get("agents", []) if a in self.agents]
            metadata = {"reasoning": data.get("reasoning", "")}
            direct_reply = data.get("direct_reply")

            # æå–æƒ…æ„Ÿæ ‡ç­¾å¹¶æ·»åŠ DEBUGæ—¥å¿—
            emotion = data.get("emotion")
            emotion_description = None
            if emotion and emotion in self.SUPPORTED_EMOTIONS:
                emotion_description = data.get("emotion_description")
                logger.debug(f"ğŸ­ [EMOTION EXTRACT] Extracted emotion from LLM response: emotion={emotion}, emotion_description={emotion_description}")
                metadata["emotion"] = emotion
                if emotion_description:
                    metadata["emotion_description"] = emotion_description
            else:
                logger.debug(f"ğŸ­ [EMOTION EXTRACT] No valid emotion extracted from LLM response: raw_emotion={emotion}")

            memory_data = data.get("memory", {})
            memory_analysis = MemoryAnalysis(
                is_important=memory_data.get("is_important", False),
                importance_level=memory_data.get("importance_level"),
                event_type=memory_data.get("event_type"),
                event_summary=memory_data.get("event_summary"),
                keywords=memory_data.get("keywords", []),
                event_date=memory_data.get("event_date"),
                raw_date_expression=memory_data.get("raw_date_expression"),
            )

            # è§£æå¯¹è¯æ‘˜è¦
            conversation_summary = data.get("conversation_summary")
            if conversation_summary:
                metadata["conversation_summary"] = conversation_summary
                logger.debug(f"ğŸ“ [SUMMARY] Generated summary: {conversation_summary.get('summary_text', '')[:50]}...")

            logger.info(f"ğŸ“Œ ç»Ÿä¸€æ¨¡å¼ | intent={intent} | is_important={memory_analysis.is_important} | emotion={emotion}" + (f" | emotion_description={emotion_description}" if emotion_description else ""))
            return intent, agents, metadata, IntentSource.LLM_UNIFIED, direct_reply, memory_analysis

        except Exception as e:
            logger.error(f"ç»Ÿä¸€åˆ†æå‡ºé”™: {e}")
            if selected_by_confidence:
                return IntentType.SINGLE_AGENT, [
                    selected_by_confidence[0][0].name], {}, IntentSource.FALLBACK, None, None
            return IntentType.DIRECT_RESPONSE, [], {}, IntentSource.FALLBACK, None, None

    def _build_capabilities(self) -> List[AgentCapability]:
        """æ„å»ºæ‰€æœ‰Agentçš„èƒ½åŠ›æè¿°åˆ—è¡¨"""
        capabilities = []
        for name, agent in self.agents.items():
            cap = AgentCapability(
                name=name,
                description=agent.description,
                keywords=getattr(agent, '_emotional_keywords', []) or 
                         getattr(agent, '_tech_keywords', []) or 
                         getattr(agent, '_tool_keywords', []),
                is_tool=name.lower().endswith('agent') and 'tool' in name.lower()
            )
            capabilities.append(cap)
        return capabilities
    
    def _get_capabilities_prompt(self) -> str:
        """ç”ŸæˆAgentèƒ½åŠ›æè¿°çš„æç¤ºè¯"""
        cap_list = []
        for cap in self._capabilities:
            cap_type = "å·¥å…·" if cap.is_tool else "Agent"
            cap_list.append(f"- {cap.name} ({cap_type}): {cap.description}")
        return "\n".join(cap_list)
    
    async def analyze_intent(
        self,
        message: Message,
        context: ChatContext
    ) -> Tuple[IntentType, List[str], Dict[str, Any], IntentSource]:
        """
        åˆ†æç”¨æˆ·æ¶ˆæ¯çš„æ„å›¾
        
        ä½¿ç”¨LLMåˆ†ææ¶ˆæ¯å†…å®¹ï¼Œåˆ¤æ–­éœ€è¦è°ƒç”¨å“ªäº›Agentã€‚
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            
        Returns:
            Tuple[IntentType, List[str], Dict, IntentSource]: 
                (æ„å›¾ç±»å‹, é€‰ä¸­çš„Agentåç§°åˆ—è¡¨, å…ƒæ•°æ®, æ„å›¾è¯†åˆ«æ¥æº)
        """
        # é¦–å…ˆä½¿ç”¨Routerçš„åŸºäºè§„åˆ™çš„ç½®ä¿¡åº¦è¯„ä¼°
        selected_by_confidence = self._router.select_agents(message, context)
        
        # å¦‚æœæ²¡æœ‰LLMæä¾›è€…ï¼Œç›´æ¥ä½¿ç”¨åŸºäºè§„åˆ™çš„ç»“æœ
        if not self.llm_provider:
            logger.info("ğŸ“Œ æ„å›¾è¯†åˆ«æ¥æº: åŸºäºè§„åˆ™ (æ— LLMæä¾›è€…)")
            if not selected_by_confidence:
                return IntentType.DIRECT_RESPONSE, [], {}, IntentSource.RULE_BASED
            elif len(selected_by_confidence) == 1:
                return IntentType.SINGLE_AGENT, [selected_by_confidence[0][0].name], {}, IntentSource.RULE_BASED
            else:
                agent_names = [agent.name for agent, _ in selected_by_confidence]
                return IntentType.MULTI_AGENT, agent_names, {}, IntentSource.RULE_BASED
        
        # ä½¿ç”¨LLMè¿›è¡Œæ›´ç²¾ç¡®çš„æ„å›¾è¯†åˆ«
        try:
            intent_prompt = f"""åˆ†æä»¥ä¸‹ç”¨æˆ·æ¶ˆæ¯ï¼Œåˆ¤æ–­åº”è¯¥å¦‚ä½•å¤„ç†ã€‚

å¯ç”¨çš„Agentèƒ½åŠ›:
{self._get_capabilities_prompt()}

ç”¨æˆ·æ¶ˆæ¯: {message.content}

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µ:
- intent: "direct_response" | "single_agent" | "multi_agent" | "tool_call"
- agents: [é€‰ä¸­çš„Agentåç§°åˆ—è¡¨]
- reasoning: é€‰æ‹©åŸå› 

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

            response = await self.llm_provider.generate_response(
                [{"role": "user", "content": intent_prompt}],
                context="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è·¯ç”±åŠ©æ‰‹ï¼Œè´Ÿè´£åˆ†æç”¨æˆ·æ„å›¾å¹¶é€‰æ‹©åˆé€‚çš„å¤„ç†æ–¹å¼ã€‚"
            )
            
            # è§£æLLMå“åº”
            try:
                # å°è¯•æå–JSON
                response_text = response.strip()
                if response_text.startswith("```"):
                    response_text = response_text.split("```")[1]
                    if response_text.startswith("json"):
                        response_text = response_text[4:]
                
                result = json.loads(response_text)
                intent = IntentType(result.get("intent", "direct_response"))
                agents = result.get("agents", [])
                metadata = {"reasoning": result.get("reasoning", "")}
                
                # éªŒè¯Agentåç§°
                valid_agents = [a for a in agents if a in self.agents]
                
                logger.info("ğŸ“Œ æ„å›¾è¯†åˆ«æ¥æº: åŸºäºLLMæ¨ç†")
                return intent, valid_agents, metadata, IntentSource.LLM_BASED
                
            except (json.JSONDecodeError, ValueError) as e:
                logger.warning(f"è§£æLLMæ„å›¾å“åº”å¤±è´¥: {e}")
                logger.info("ğŸ“Œ æ„å›¾è¯†åˆ«æ¥æº: å›é€€åˆ°è§„åˆ™ (LLMè§£æå¤±è´¥)")
                # å›é€€åˆ°åŸºäºè§„åˆ™çš„ç»“æœ
                if selected_by_confidence:
                    agent_names = [agent.name for agent, _ in selected_by_confidence]
                    intent = IntentType.SINGLE_AGENT if len(agent_names) == 1 else IntentType.MULTI_AGENT
                    return intent, agent_names, {}, IntentSource.FALLBACK
                return IntentType.DIRECT_RESPONSE, [], {}, IntentSource.FALLBACK
                
        except Exception as e:
            logger.error(f"LLMæ„å›¾åˆ†æå‡ºé”™: {e}")
            logger.info("ğŸ“Œ æ„å›¾è¯†åˆ«æ¥æº: å›é€€åˆ°è§„åˆ™ (LLMè°ƒç”¨å¤±è´¥)")
            # å›é€€åˆ°åŸºäºè§„åˆ™çš„ç»“æœ
            if selected_by_confidence:
                agent_names = [agent.name for agent, _ in selected_by_confidence]
                intent = IntentType.SINGLE_AGENT if len(agent_names) == 1 else IntentType.MULTI_AGENT
                return intent, agent_names, {}, IntentSource.FALLBACK
            return IntentType.DIRECT_RESPONSE, [], {}, IntentSource.FALLBACK
    
    def generate_skill_options(
        self,
        message: Message,
        context: ChatContext
    ) -> List[Dict[str, str]]:
        """
        ç”ŸæˆæŠ€èƒ½é€‰é¡¹ä¾›ç”¨æˆ·é€‰æ‹©
        
        å½“æœ‰å¤šä¸ªå¯èƒ½çš„Agentæ—¶ï¼Œç”ŸæˆTelegramæŒ‰é’®é€‰é¡¹ï¼Œ
        è®©ç”¨æˆ·ä¸»åŠ¨é€‰æ‹©ï¼Œä»¥èŠ‚çœtokenæ¶ˆè€—ã€‚
        
        Returns:
            List[Dict]: åŒ…å«button_textå’Œcallback_dataçš„é€‰é¡¹åˆ—è¡¨
        """
        options = []
        selected = self._router.select_agents(message, context)
        
        for agent, confidence in selected[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ªé€‰é¡¹
            options.append({
                "button_text": f"{agent.name}",
                "callback_data": f"skill:{agent.name}",
                "description": agent.description[:50] + "..." if len(agent.description) > 50 else agent.description,
                "confidence": confidence
            })
        
        return options
    
    async def execute_agents(
        self,
        message: Message,
        context: ChatContext,
        agent_names: List[str]
    ) -> List[AgentResponse]:
        """
        æ‰§è¡ŒæŒ‡å®šçš„Agentå¹¶æ”¶é›†å“åº”
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            agent_names: è¦æ‰§è¡Œçš„Agentåç§°åˆ—è¡¨
            
        Returns:
            List[AgentResponse]: Agentå“åº”åˆ—è¡¨
        """
        responses = []
        
        for agent_name in agent_names:
            if agent_name not in self.agents:
                logger.warning(f"Agentæœªæ‰¾åˆ°: {agent_name}")
                continue
            
            agent = self.agents[agent_name]
            try:
                response = agent.respond(message, context)
                responses.append(response)
                logger.info(f"Agent {agent_name} å“åº”æˆåŠŸ")
            except Exception as e:
                logger.error(f"Agent {agent_name} æ‰§è¡Œå¤±è´¥: {e}")
        
        return responses
    
    async def synthesize_response(
        self,
        message: Message,
        agent_responses: List[AgentResponse],
        context: ChatContext
    ) -> str:
        """
        ç»¼åˆå¤šä¸ªAgentçš„å“åº”ç”Ÿæˆæœ€ç»ˆå›å¤
        
        ä½¿ç”¨LLMæ•´åˆæ‰€æœ‰Agentçš„è¾“å‡ºï¼Œç”Ÿæˆç»Ÿä¸€è¿è´¯çš„å›å¤ã€‚
        
        Args:
            message: åŸå§‹ç”¨æˆ·æ¶ˆæ¯
            agent_responses: å„Agentçš„å“åº”
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            
        Returns:
            str: æœ€ç»ˆç»¼åˆå›å¤
        """
        if not agent_responses:
            return "æŠ±æ­‰ï¼Œæˆ‘ç›®å‰æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚è¯·ç¨åå†è¯•ã€‚"
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªå“åº”ï¼Œç›´æ¥è¿”å›
        if len(agent_responses) == 1:
            return agent_responses[0].content
        
        # å¦‚æœæ²¡æœ‰LLMæä¾›è€…ï¼Œç®€å•æ‹¼æ¥å“åº”
        if not self.llm_provider:
            combined = []
            for resp in agent_responses:
                combined.append(f"ã€{resp.agent_name}ã€‘\n{resp.content}")
            return "\n\n".join(combined)
        
        # ä½¿ç”¨LLMç»¼åˆå¤šä¸ªå“åº”
        try:
            responses_text = ""
            for resp in agent_responses:
                responses_text += f"\n[{resp.agent_name}çš„åˆ†æ]:\n{resp.content}\n"
            
            synthesis_prompt = f"""ç”¨æˆ·é—®é¢˜: {message.content}

å„ä¸“å®¶çš„åˆ†æç»“æœ:
{responses_text}

è¯·ç»¼åˆä»¥ä¸Šå„ä¸“å®¶çš„åˆ†æï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´ã€è¿è´¯çš„å›å¤ç»™ç”¨æˆ·ã€‚
è¦æ±‚ï¼š
1. æ•´åˆå„ä¸“å®¶çš„è§‚ç‚¹
2. ä¿æŒè¯­æ°”ä¸€è‡´å’Œè‡ªç„¶
3. ä¸è¦æåŠ"ä¸“å®¶"æˆ–"åˆ†æç»“æœ"
4. ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜
5. å›å¤å†…å®¹ä¸­ä¸è¦åŒ…å«è¯­æ°”æ ‡æ³¨ï¼Œç›´æ¥è¾“å‡ºçº¯æ–‡æœ¬å›å¤"""

            final_response = await self.llm_provider.generate_response(
                [{"role": "user", "content": synthesis_prompt}],
                context="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œè´Ÿè´£æ•´åˆå¤šä¸ªä¸“å®¶çš„æ„è§ç»™ç”¨æˆ·æä¾›å®Œæ•´çš„å›ç­”ã€‚"
            )
            
            return final_response
            
        except Exception as e:
            logger.error(f"ç»¼åˆå“åº”ç”Ÿæˆå¤±è´¥: {e}")
            # å›é€€åˆ°ç®€å•æ‹¼æ¥
            return agent_responses[0].content

    async def process(
            self,
            message: Message,
            context: ChatContext,
            force_skill_selection: bool = False
    ) -> OrchestratorResult:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯çš„ä¸»å…¥å£"""
        result = OrchestratorResult(intent_type=IntentType.DIRECT_RESPONSE)

        # æ ¹æ®é…ç½®é€‰æ‹©å¤„ç†æ¨¡å¼
        if self.enable_unified_mode and self.llm_provider:
            # ğŸ”‘ ç»Ÿä¸€æ¨¡å¼
            intent_type, agent_names, metadata, intent_source, direct_reply, memory_analysis = \
                await self.analyze_intent_unified(message, context)

            result.intent_type = intent_type
            result.intent_source = intent_source
            result.selected_agents = agent_names
            result.metadata = metadata
            result.metadata["intent_source"] = intent_source.value
            result.memory_analysis = memory_analysis
        else:
            # åŸæœ‰æ¨¡å¼
            intent_type, agent_names, metadata, intent_source = await self.analyze_intent(message, context)
            result.intent_type = intent_type
            result.intent_source = intent_source
            result.selected_agents = agent_names
            result.metadata = metadata
            result.metadata["intent_source"] = intent_source.value
            direct_reply = None

        logger.info(f"ğŸ¯ Intent type: {result.intent_type} | Source: {result.intent_source}")

        # æŠ€èƒ½é€‰æ‹©æ£€æŸ¥
        if self.enable_skills and (force_skill_selection or len(result.selected_agents) >= self.skill_threshold):
            skill_options = self.generate_skill_options(message, context)
            if skill_options:
                result.intent_type = IntentType.SKILL_SELECTION
                result.skill_options = skill_options
                result.final_response = "è¯·é€‰æ‹©æ‚¨éœ€è¦çš„æœåŠ¡ï¼š"
                return result

        # ç›´æ¥å“åº”
        if result.intent_type == IntentType.DIRECT_RESPONSE or not result.selected_agents:
            if direct_reply:
                result.final_response = direct_reply
            elif self.llm_provider:
                try:
                    messages = []
                    if context and context.system_prompt:
                        messages.append({"role": "system", "content": context.system_prompt})
                    messages.append({"role": "user", "content": message.content})
                    result.final_response = await self.llm_provider.generate_response(messages, context=None)
                except Exception as e:
                    logger.error(f"ç›´æ¥å“åº”ç”Ÿæˆå¤±è´¥: {e}")
                    result.final_response = "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"
            else:
                result.final_response = "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"
            return result

        # Agent å¤„ç†
        agent_responses = await self.execute_agents(message, context, result.selected_agents)
        result.agent_responses = agent_responses
        result.final_response = await self.synthesize_response(message, agent_responses, context)

        return result

    async def process_skill_callback(
        self,
        skill_name: str,
        message: Message,
        context: ChatContext
    ) -> OrchestratorResult:
        """
        å¤„ç†ç”¨æˆ·çš„æŠ€èƒ½é€‰æ‹©å›è°ƒ
        
        å½“ç”¨æˆ·ç‚¹å‡»æŠ€èƒ½æŒ‰é’®åï¼Œæ‰§è¡Œç›¸åº”çš„Agentã€‚
        
        Args:
            skill_name: ç”¨æˆ·é€‰æ‹©çš„æŠ€èƒ½ï¼ˆAgentï¼‰åç§°
            message: åŸå§‹ç”¨æˆ·æ¶ˆæ¯
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            
        Returns:
            OrchestratorResult: å¤„ç†ç»“æœ
        """
        result = OrchestratorResult(
            intent_type=IntentType.SINGLE_AGENT,
            selected_agents=[skill_name]
        )
        
        if skill_name not in self.agents:
            result.final_response = f"æŠ±æ­‰ï¼ŒæŠ€èƒ½ '{skill_name}' ä¸å¯ç”¨ã€‚"
            return result
        
        # æ‰§è¡Œé€‰ä¸­çš„Agent
        agent_responses = await self.execute_agents(message, context, [skill_name])
        result.agent_responses = agent_responses
        
        if agent_responses:
            result.final_response = agent_responses[0].content
        else:
            result.final_response = "æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ã€‚"
        
        return result
    
    def add_agent(self, agent: BaseAgent) -> None:
        """åŠ¨æ€æ·»åŠ Agent"""
        self.agents[agent.name] = agent
        self._capabilities = self._build_capabilities()
        self._router.add_agent(agent)
        logger.info(f"æ·»åŠ Agent: {agent.name}")
    
    def remove_agent(self, agent_name: str) -> bool:
        """åŠ¨æ€ç§»é™¤Agent"""
        if agent_name in self.agents:
            del self.agents[agent_name]
            self._capabilities = self._build_capabilities()
            self._router.remove_agent(agent_name)
            logger.info(f"ç§»é™¤Agent: {agent_name}")
            return True
        return False
