"""
è¯­éŸ³å‘½ä»¤å¤„ç†å™¨
å¤„ç†ç”¨æˆ·å¼€å¯/å…³é—­è¯­éŸ³å›å¤çš„å‘½ä»¤ï¼Œä»¥åŠæ¥æ”¶ç”¨æˆ·è¯­éŸ³æ¶ˆæ¯å¹¶è¿›è¡Œè¯†åˆ«
"""
import os
import tempfile
import subprocess
from pathlib import Path
from datetime import datetime
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes, CommandHandler, CallbackQueryHandler, MessageHandler, filters
from loguru import logger

from src.services.voice_preference_service import voice_preference_service
from src.services.voice_recognition_service import voice_recognition_service
from src.utils.voice_helper import build_voice_recognition_prompt


# ç”¨æˆ·è¯­éŸ³æ–‡ä»¶å­˜å‚¨åŸºç¡€ç›®å½•
VOICE_STORAGE_BASE_DIR = Path("data/voice")


def get_user_voice_storage_path(user_id: int) -> Path:
    """
    è·å–ç”¨æˆ·è¯­éŸ³æ–‡ä»¶å­˜å‚¨è·¯å¾„

    è·¯å¾„æ ¼å¼: data/voice/{user_id}/{æ—¥æœŸ(YYYY-MM-DD)}/

    Args:
        user_id: ç”¨æˆ·ID

    Returns:
        ç”¨æˆ·å½“å¤©çš„è¯­éŸ³å­˜å‚¨ç›®å½•è·¯å¾„
    """
    current_date = datetime.now().strftime("%Y-%m-%d")
    voice_dir = VOICE_STORAGE_BASE_DIR / str(user_id) / current_date
    voice_dir.mkdir(parents=True, exist_ok=True)
    return voice_dir


def generate_voice_filename() -> str:
    """
    ç”Ÿæˆè¯­éŸ³æ–‡ä»¶å

    æ–‡ä»¶åæ ¼å¼: {æ—¶-åˆ†-ç§’}.mp3

    Returns:
        ç”Ÿæˆçš„æ–‡ä»¶å
    """
    current_time = datetime.now().strftime("%H-%M-%S")
    return f"{current_time}.mp3"


async def convert_ogg_to_mp3(ogg_path: str, mp3_path: str) -> bool:
    """
    å°† OGG æ ¼å¼éŸ³é¢‘è½¬æ¢ä¸º MP3 æ ¼å¼

    ä½¿ç”¨ ffmpeg è¿›è¡Œè½¬æ¢

    Args:
        ogg_path: OGG æ–‡ä»¶è·¯å¾„
        mp3_path: ç›®æ ‡ MP3 æ–‡ä»¶è·¯å¾„

    Returns:
        è½¬æ¢æ˜¯å¦æˆåŠŸ
    """
    try:
        # ä½¿ç”¨ ffmpeg è½¬æ¢ï¼Œ-y è¡¨ç¤ºè¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
        result = subprocess.run(
            ["ffmpeg", "-y", "-i", ogg_path, "-acodec", "libmp3lame", "-q:a", "2", mp3_path],
            capture_output=True,
            text=True,
            timeout=30
        )

        if result.returncode == 0:
            logger.info(f"ğŸ™ï¸ [VOICE] Successfully converted {ogg_path} to {mp3_path}")
            return True
        else:
            logger.error(f"ğŸ™ï¸ [VOICE] ffmpeg conversion failed: {result.stderr}")
            return False

    except FileNotFoundError:
        logger.error("ğŸ™ï¸ [VOICE] ffmpeg not found. Please install ffmpeg.")
        return False
    except subprocess.TimeoutExpired:
        logger.error("ğŸ™ï¸ [VOICE] ffmpeg conversion timed out")
        return False
    except Exception as e:
        logger.error(f"ğŸ™ï¸ [VOICE] Error during audio conversion: {e}")
        return False


async def voice_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    /voice å‘½ä»¤ - æ˜¾ç¤ºè¯­éŸ³è®¾ç½®èœå•
    """
    user_id = update.effective_user.id
    bot_username = context.bot.username

    logger.info(f"ğŸ¤ [VOICE CMD] /voice command received from user_id={user_id}, bot=@{bot_username}")

    # è·å–å½“å‰çŠ¶æ€
    is_enabled = voice_preference_service.is_voice_enabled(user_id, bot_username)
    status = "âœ… å·²å¼€å¯" if is_enabled else "âŒ å·²å…³é—­"

    logger.info(f"ğŸ¤ [VOICE CMD] Current voice status for user_id={user_id}: enabled={is_enabled}")

    # åˆ›å»ºæŒ‰é’®
    keyboard = [
        [
            InlineKeyboardButton(
                "ğŸ¤ å¼€å¯è¯­éŸ³" if not is_enabled else "ğŸ“ å…³é—­è¯­éŸ³",
                callback_data=f"voice_toggle"
            )
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    await update.message.reply_text(
        f"ğŸ™ï¸ **è¯­éŸ³å›å¤è®¾ç½®**\n\n"
        f"å½“å‰çŠ¶æ€: {status}\n\n"
        f"å¼€å¯åï¼Œæˆ‘ä¼šç”¨è¯­éŸ³å›å¤ä½ çš„æ¶ˆæ¯~",
        reply_markup=reply_markup,
        parse_mode="Markdown"
    )
    logger.info(f"ğŸ¤ [VOICE CMD] Voice settings menu sent to user_id={user_id}")


async def voice_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    å¤„ç†è¯­éŸ³è®¾ç½®æŒ‰é’®å›è°ƒ
    """
    query = update.callback_query
    await query.answer()

    user_id = update.effective_user.id
    bot_username = context.bot.username

    logger.info(f"ğŸ¤ [VOICE CALLBACK] Voice toggle callback received from user_id={user_id}, bot=@{bot_username}")

    if query.data == "voice_toggle":
        # åˆ‡æ¢çŠ¶æ€
        new_state = voice_preference_service.toggle_voice(user_id, bot_username)
        logger.info(f"ğŸ¤ [VOICE CALLBACK] Voice preference toggled for user_id={user_id}: new_state={new_state}")

        if new_state:
            status = "âœ… å·²å¼€å¯"
            message = "ğŸ¤ è¯­éŸ³å›å¤åŠŸèƒ½å·²å¼€å¯ï¼Œåç»­çš„å¯¹è¯å°†ä½¿ç”¨è¯­éŸ³è¿›è¡Œå›å¤"
            button_text = "ğŸ“ å…³é—­è¯­éŸ³"
        else:
            status = "âŒ å·²å…³é—­"
            message = "ğŸ“ è¯­éŸ³å›å¤åŠŸèƒ½å·²å…³é—­ï¼Œåç»­çš„å¯¹è¯å°†ä½¿ç”¨æ–‡æœ¬è¿›è¡Œå›å¤"
            button_text = "ğŸ¤ å¼€å¯è¯­éŸ³"

        # æ–°æŒ‰é’®
        keyboard = [[InlineKeyboardButton(button_text, callback_data="voice_toggle")]]
        reply_markup = InlineKeyboardMarkup(keyboard)

        await query.edit_message_text(
            f"ğŸ™ï¸ **è¯­éŸ³å›å¤è®¾ç½®**\n\n"
            f"å½“å‰çŠ¶æ€: {status}\n\n"
            f"{message}",
            reply_markup=reply_markup,
            parse_mode="Markdown"
        )
        logger.info(f"ğŸ¤ [VOICE CALLBACK] Voice settings updated for user_id={user_id}")


async def voice_on_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    /voice_on å‘½ä»¤ - å¿«é€Ÿå¼€å¯è¯­éŸ³
    """
    user_id = update.effective_user.id
    bot_username = context.bot.username

    logger.info(f"ğŸ¤ [VOICE ON] /voice_on command received from user_id={user_id}, bot=@{bot_username}")

    voice_preference_service.set_voice_enabled(user_id, bot_username, True)
    logger.info(f"ğŸ¤ [VOICE ON] Voice preference set to enabled for user_id={user_id}")

    # ä»…å‘é€æ–‡æœ¬æç¤ºæ¶ˆæ¯
    confirmation_text = "ğŸ¤ è¯­éŸ³å›å¤åŠŸèƒ½å·²å¼€å¯ï¼Œåç»­çš„å¯¹è¯å°†ä½¿ç”¨è¯­éŸ³è¿›è¡Œå›å¤"
    await update.message.reply_text(confirmation_text)
    logger.info(f"ğŸ¤ [VOICE ON] Confirmation sent for user_id={user_id}")


async def voice_off_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    /voice_off å‘½ä»¤ - å¿«é€Ÿå…³é—­è¯­éŸ³
    """
    user_id = update.effective_user.id
    bot_username = context.bot.username

    logger.info(f"ğŸ¤ [VOICE OFF] /voice_off command received from user_id={user_id}, bot=@{bot_username}")

    # å…³é—­è¯­éŸ³è®¾ç½®
    voice_preference_service.set_voice_enabled(user_id, bot_username, False)
    logger.info(f"ğŸ¤ [VOICE OFF] Voice preference set to disabled for user_id={user_id}")

    # ä»…å‘é€æ–‡æœ¬æç¤ºæ¶ˆæ¯
    confirmation_text = "ğŸ“ è¯­éŸ³å›å¤åŠŸèƒ½å·²å…³é—­ï¼Œåç»­çš„å¯¹è¯å°†ä½¿ç”¨æ–‡æœ¬è¿›è¡Œå›å¤"
    await update.message.reply_text(confirmation_text)
    logger.info(f"ğŸ¤ [VOICE OFF] Confirmation sent for user_id={user_id}")


async def handle_voice_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    å¤„ç†ç”¨æˆ·å‘é€çš„è¯­éŸ³æ¶ˆæ¯

    æµç¨‹ï¼š
    1. ä¸‹è½½ç”¨æˆ·å‘é€çš„è¯­éŸ³æ–‡ä»¶ï¼ˆOGG æ ¼å¼ï¼‰
    2. å°†è¯­éŸ³æ–‡ä»¶ä¿å­˜åˆ° data/voice/{user_id}/{æ—¥æœŸ}/{æ—¶é—´}.mp3
    3. è°ƒç”¨ DashScope ASR æœåŠ¡è¿›è¡Œè¯­éŸ³è¯†åˆ«
    4. å°†è¯†åˆ«å‡ºçš„æ–‡æœ¬å’Œæƒ…ç»ªæ„å»ºä¸º LLM æç¤º
    5. è°ƒç”¨ agent_integration çš„æ¶ˆæ¯å¤„ç†æµç¨‹è·å– AI å›å¤
    6. å‘é€å›å¤ç»™ç”¨æˆ·
    """
    message = update.message
    if not message or not message.voice:
        logger.warning("âŒ [VOICE MSG] No voice message found in update")
        return

    user_id = update.effective_user.id if update.effective_user else None
    chat_id = message.chat.id

    logger.info(
        f"ğŸ™ï¸ [VOICE MSG] Voice message received from user_id={user_id}, "
        f"duration={message.voice.duration}s, file_size={message.voice.file_size}"
    )

    # å‘é€ typing æŒ‡ç¤º
    await message.chat.send_action("typing")

    tmp_ogg_path = None
    saved_mp3_path = None

    try:
        # 1. ä¸‹è½½è¯­éŸ³æ–‡ä»¶
        voice_file = await message.voice.get_file()

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜åŸå§‹ OGG è¯­éŸ³
        with tempfile.NamedTemporaryFile(
            suffix=".ogg", delete=False, dir=tempfile.gettempdir()
        ) as tmp_file:
            tmp_ogg_path = tmp_file.name

        await voice_file.download_to_drive(tmp_ogg_path)
        logger.info(f"ğŸ™ï¸ [VOICE MSG] Voice file downloaded to temp: {tmp_ogg_path}")

        # 2. ä¿å­˜è¯­éŸ³æ–‡ä»¶åˆ°ç”¨æˆ·ç›®å½• (è½¬æ¢ä¸º MP3 æ ¼å¼)
        if user_id:
            user_voice_dir = get_user_voice_storage_path(user_id)
            voice_filename = generate_voice_filename()
            saved_mp3_path = str(user_voice_dir / voice_filename)

            # è½¬æ¢ OGG åˆ° MP3
            conversion_success = await convert_ogg_to_mp3(tmp_ogg_path, saved_mp3_path)

            if conversion_success:
                logger.info(f"ğŸ™ï¸ [VOICE MSG] Voice file saved to: {saved_mp3_path}")
            else:
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œç›´æ¥å¤åˆ¶ OGG æ–‡ä»¶ï¼ˆæ”¹åä¸º .mp3 åç¼€ï¼‰
                logger.warning("ğŸ™ï¸ [VOICE MSG] MP3 conversion failed, saving OGG file instead")
                import shutil
                saved_mp3_path = str(user_voice_dir / voice_filename.replace('.mp3', '.ogg'))
                shutil.copy(tmp_ogg_path, saved_mp3_path)
                logger.info(f"ğŸ™ï¸ [VOICE MSG] Voice file saved as OGG: {saved_mp3_path}")

        # 3. è°ƒç”¨è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼ˆä½¿ç”¨ä¿å­˜çš„ MP3 æ–‡ä»¶ï¼‰
        # æ³¨æ„ï¼šDashScope ASR æ”¯æŒ mp3/ogg/wav ç­‰æ ¼å¼
        asr_file_path = saved_mp3_path if saved_mp3_path and os.path.exists(saved_mp3_path) else tmp_ogg_path
        recognition_result = await voice_recognition_service.recognize_voice(asr_file_path)

        if not recognition_result.text:
            logger.warning("ğŸ™ï¸ [VOICE MSG] Voice recognition returned empty text")
            await message.reply_text("ğŸ™ï¸ æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰å¬æ¸…ä½ è¯´çš„å†…å®¹ï¼Œè¯·å†è¯•ä¸€æ¬¡~")
            return

        logger.info(
            f"ğŸ™ï¸ [VOICE MSG] Recognition result: text='{recognition_result.text[:100]}', "
            f"emotion={recognition_result.emotion}"
        )

        # 4. æ„å»ºåŒ…å«è¯­éŸ³ä¿¡æ¯çš„æç¤ºæ–‡æœ¬
        enhanced_text = build_voice_recognition_prompt(
            recognized_text=recognition_result.text,
            emotion=recognition_result.emotion,
        )

        # 5. å°†è¯­éŸ³è¯†åˆ«ç»“æœä½œä¸ºæ–‡æœ¬æ¶ˆæ¯æ³¨å…¥åˆ° agent å¤„ç†æµç¨‹
        # é€šè¿‡æ¨¡æ‹Ÿæ–‡æœ¬æ¶ˆæ¯ï¼Œå¤ç”¨ç°æœ‰çš„ handle_message_with_agents é€»è¾‘
        from src.handlers.agent_integration import handle_message_with_agents

        # ä¿å­˜åŸå§‹æ–‡æœ¬ï¼Œæ›¿æ¢ä¸ºè¯­éŸ³è¯†åˆ«å¢å¼ºæ–‡æœ¬
        original_text = message.text
        message.text = enhanced_text

        # åœ¨ context ä¸­æ ‡è®°è¿™æ˜¯ä¸€æ¡è¯­éŸ³æ¶ˆæ¯ï¼Œä¾›åç»­å¤„ç†ä½¿ç”¨
        context.user_data["voice_input"] = True
        context.user_data["voice_recognized_text"] = recognition_result.text
        context.user_data["voice_emotion"] = recognition_result.emotion
        context.user_data["voice_file_path"] = saved_mp3_path  # ä¿å­˜è¯­éŸ³æ–‡ä»¶è·¯å¾„

        logger.info(f"ğŸ™ï¸ [VOICE MSG] Forwarding to agent handler: '{enhanced_text[:100]}'")

        await handle_message_with_agents(update, context)

        # æ¸…ç† context æ ‡è®°
        context.user_data.pop("voice_input", None)
        context.user_data.pop("voice_recognized_text", None)
        context.user_data.pop("voice_emotion", None)
        context.user_data.pop("voice_file_path", None)

        # æ¢å¤åŸå§‹æ–‡æœ¬
        message.text = original_text

    except Exception as e:
        logger.error(f"âŒ [VOICE MSG] Error processing voice message: {e}", exc_info=True)
        await message.reply_text(
            "ğŸ™ï¸ æŠ±æ­‰ï¼Œå¤„ç†è¯­éŸ³æ¶ˆæ¯æ—¶é‡åˆ°äº†é—®é¢˜ï¼Œè¯·ç¨åå†è¯•~"
        )
    finally:
        # æ¸…ç†ä¸´æ—¶ OGG æ–‡ä»¶
        if tmp_ogg_path and os.path.exists(tmp_ogg_path):
            try:
                os.unlink(tmp_ogg_path)
                logger.debug(f"ğŸ™ï¸ [VOICE MSG] Temp OGG file cleaned: {tmp_ogg_path}")
            except OSError as e:
                logger.warning(f"ğŸ™ï¸ [VOICE MSG] Failed to clean temp file: {e}")


def get_voice_handlers():
    """
    è·å–è¯­éŸ³ç›¸å…³çš„å¤„ç†å™¨
    """
    return [
        CommandHandler("voice", voice_command),
        CommandHandler("voice_on", voice_on_command),
        CommandHandler("voice_off", voice_off_command),
        CallbackQueryHandler(voice_callback, pattern="^voice_"),
        MessageHandler(filters.VOICE, handle_voice_message),
    ]