"""
Emotion parser utility for LLM responses
ä»LLMå“åº”ä¸­è§£æè¯­æ°”æ ‡ç­¾å¹¶åˆ†ç¦»å¹²å‡€æ–‡æœ¬

Supports two formats:
1. Legacy prefix format: ï¼ˆè¯­æ°”ï¼šå¼€å¿ƒã€è½»å¿«ã€å…´å¥‹ï¼Œè¯­é€Ÿç¨å¿«ï¼Œè¯­è°ƒä¸Šæ‰¬ï¼‰è¿™æ˜¯å†…å®¹
2. JSON format: {"response": "è¿™æ˜¯å†…å®¹", "emotion_info": {"emotion_type": "happy", "intensity": "high", "tone_description": "å¼€å¿ƒã€è½»å¿«"}}
"""
import re
import json
from typing import Tuple, Optional, Dict, Any
from dataclasses import dataclass
from loguru import logger


# Pattern to match emotion prefix in format: ï¼ˆè¯­æ°”ï¼š...ï¼‰
# Matches Chinese parentheses ï¼ˆï¼‰containing emotion description starting with è¯­æ°”ï¼š
EMOTION_PATTERN = re.compile(r'^ï¼ˆè¯­æ°”ï¼š[^ï¼‰]+ï¼‰')

# Mapping from keywords in emotion prefix to TTS emotion tags
# Note: These keywords are extracted from common Chinese emotion descriptions
# and mapped to the TTS service's supported emotion tags
EMOTION_KEYWORDS_MAP = {
    # Happy/Excited emotions
    "å¼€å¿ƒ": "happy",
    "è½»å¿«": "happy",
    "å…´å¥‹": "excited",
    "æ´»è·ƒ": "excited",
    # Gentle/Warm emotions
    "æ¸©æŸ”": "gentle",
    "è½»å£°": "gentle",
    "æŸ”å’Œ": "gentle",
    "æ¸©æš–": "gentle",
    # Sad/Down emotions
    "ä½è½": "sad",
    "å…‹åˆ¶": "sad",
    "ä¼¤æ„Ÿ": "sad",
    "éš¾è¿‡": "sad",
    # Angry emotions
    "ç”Ÿæ°”": "angry",
    "æ„¤æ€’": "angry",
    # Crying emotions
    "å§”å±ˆ": "crying",
    "å“­æ³£": "crying",
}


@dataclass
class ParsedEmotionResponse:
    """
    è§£æåçš„æƒ…ç»ªå“åº”å¯¹è±¡
    
    Attributes:
        clean_text: å¹²å‡€çš„å“åº”æ–‡æœ¬ï¼ˆä¸åŒ…å«æƒ…ç»ªå‰ç¼€æˆ–JSONç»“æ„ï¼‰
        emotion_type: æƒ…ç»ªç±»å‹
        intensity: æƒ…ç»ªå¼ºåº¦
        tone_description: è¯­æ°”æè¿°ï¼ˆåŸå§‹ä¸­æ–‡æè¿°ï¼‰
    """
    clean_text: str
    emotion_type: Optional[str] = None
    intensity: Optional[str] = None
    tone_description: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "clean_text": self.clean_text,
            "emotion_type": self.emotion_type,
            "intensity": self.intensity,
            "tone_description": self.tone_description
        }
    
    def get_emotion_info_dict(self) -> Optional[Dict[str, Any]]:
        """è·å–æƒ…ç»ªä¿¡æ¯å­—å…¸ï¼ˆä¸åŒ…å«clean_textï¼‰"""
        if not self.emotion_type and not self.intensity and not self.tone_description:
            return None
        return {
            "emotion_type": self.emotion_type,
            "intensity": self.intensity,
            "tone_description": self.tone_description
        }


def parse_llm_response_with_emotion(response: str) -> ParsedEmotionResponse:
    """
    è§£æLLMå“åº”ï¼Œæå–æƒ…ç»ªä¿¡æ¯å’Œå¹²å‡€æ–‡æœ¬ã€‚
    
    æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
    1. JSONæ ¼å¼ï¼š{"response": "...", "emotion_info": {...}}
    2. å‰ç¼€æ ¼å¼ï¼šï¼ˆè¯­æ°”ï¼š...ï¼‰å†…å®¹
    
    Args:
        response: LLMåŸå§‹å“åº”
        
    Returns:
        ParsedEmotionResponseå¯¹è±¡ï¼ŒåŒ…å«å¹²å‡€æ–‡æœ¬å’Œæƒ…ç»ªä¿¡æ¯
    """
    if not response:
        return ParsedEmotionResponse(clean_text="")
    
    # Try to parse as JSON first
    json_result = _try_parse_json_format(response)
    if json_result:
        logger.debug(f"ğŸ­ Parsed JSON emotion format: emotion_type={json_result.emotion_type}, intensity={json_result.intensity}")
        return json_result
    
    # Fall back to legacy prefix format
    emotion_tag, clean_text = extract_emotion_and_text(response)
    
    # If we found emotion from prefix, extract additional info
    if emotion_tag:
        # Get the prefix for tone description
        match = EMOTION_PATTERN.match(response)
        tone_desc = match.group(0)[4:-1] if match else None  # Remove ï¼ˆè¯­æ°”ï¼š and ï¼‰
        
        # Try to determine intensity from the prefix
        intensity = _parse_intensity_from_text(response)
        
        return ParsedEmotionResponse(
            clean_text=clean_text,
            emotion_type=emotion_tag,
            intensity=intensity,
            tone_description=tone_desc
        )
    
    return ParsedEmotionResponse(clean_text=clean_text)


def _try_parse_json_format(response: str) -> Optional[ParsedEmotionResponse]:
    """
    å°è¯•å°†å“åº”è§£æä¸ºJSONæ ¼å¼ã€‚
    
    æœŸæœ›æ ¼å¼ï¼š
    {
        "response": "å›å¤å†…å®¹",
        "emotion_info": {
            "emotion_type": "happy",
            "intensity": "high", 
            "tone_description": "å¼€å¿ƒã€è½»å¿«ã€å…´å¥‹"
        }
    }
    
    Args:
        response: LLMå“åº”å­—ç¬¦ä¸²
        
    Returns:
        ParsedEmotionResponseå¯¹è±¡æˆ–Noneï¼ˆå¦‚æœä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼‰
    """
    try:
        # Try to find JSON in the response
        # The response might be pure JSON or JSON wrapped in text
        stripped = response.strip()
        
        # Check if it starts with { and ends with }
        if not (stripped.startswith('{') and stripped.endswith('}')):
            return None
        
        data = json.loads(stripped)
        
        # Check required fields
        if "response" not in data:
            return None
        
        clean_text = data.get("response", "")
        emotion_info = data.get("emotion_info", {})
        
        # Validate emotion_info is a dict before accessing
        if emotion_info and isinstance(emotion_info, dict):
            return ParsedEmotionResponse(
                clean_text=clean_text,
                emotion_type=emotion_info.get("emotion_type"),
                intensity=emotion_info.get("intensity"),
                tone_description=emotion_info.get("tone_description")
            )
        else:
            return ParsedEmotionResponse(clean_text=clean_text)
            
    except (json.JSONDecodeError, TypeError, AttributeError):
        return None


def _parse_intensity_from_text(text: str) -> str:
    """
    ä»æ–‡æœ¬ä¸­è§£ææƒ…ç»ªå¼ºåº¦ã€‚
    
    Args:
        text: åŒ…å«æƒ…ç»ªæè¿°çš„æ–‡æœ¬
        
    Returns:
        å¼ºåº¦çº§åˆ«ï¼ˆhigh, medium, lowï¼‰ï¼Œé»˜è®¤ä¸º medium
    """
    # Check intensity in priority order: high > medium > low
    # Group keywords by intensity level
    high_keywords = ["é«˜", "å¼º", "å¼ºçƒˆ", "éå¸¸", "æåº¦"]
    medium_keywords = ["ä¸­", "é€‚ä¸­", "ä¸€èˆ¬"]
    low_keywords = ["ä½", "è½»å¾®", "ç•¥å¾®", "æœ‰ç‚¹"]
    
    for keyword in high_keywords:
        if keyword in text:
            return "high"
    
    for keyword in medium_keywords:
        if keyword in text:
            return "medium"
    
    for keyword in low_keywords:
        if keyword in text:
            return "low"
    
    return "medium"  # Default to medium if no intensity keywords found


def extract_emotion_and_text(response: str) -> Tuple[Optional[str], str]:
    """
    Extract emotion tag and clean text from LLM response.
    
    ä»LLMå“åº”ä¸­æå–è¯­æ°”æ ‡ç­¾å’Œå¹²å‡€æ–‡æœ¬ã€‚
    
    Args:
        response: The full LLM response that may contain emotion prefix
        
    Returns:
        Tuple of (emotion_tag, clean_text) where:
        - emotion_tag: One of "happy", "gentle", "sad", "excited", "angry", "crying" or None
        - clean_text: The response text with emotion prefix stripped
        
    Examples:
        >>> extract_emotion_and_text("ï¼ˆè¯­æ°”ï¼šå¼€å¿ƒã€è½»å¿«ï¼‰ä½ å¥½å•Šï¼")
        ("happy", "ä½ å¥½å•Šï¼")
        
        >>> extract_emotion_and_text("ï¼ˆè¯­æ°”ï¼šç”Ÿæ°”ï¼Œæ„¤æ€’ï¼‰è¿™å¤ªè¿‡åˆ†äº†ï¼")
        ("angry", "è¿™å¤ªè¿‡åˆ†äº†ï¼")
        
        >>> extract_emotion_and_text("æ™®é€šå›å¤å†…å®¹")
        (None, "æ™®é€šå›å¤å†…å®¹")
    """
    if not response:
        return None, ""
    
    # Try to match emotion prefix at the start of the response
    match = EMOTION_PATTERN.match(response)
    
    if not match:
        # No emotion prefix found, return original text
        return None, response
    
    # Extract the emotion prefix
    emotion_prefix = match.group(0)
    
    # Get the clean text by removing the emotion prefix
    clean_text = response[len(emotion_prefix):].lstrip()
    
    # Determine the emotion tag based on keywords in the prefix
    emotion_tag = _parse_emotion_from_prefix(emotion_prefix)
    
    logger.debug(f"ğŸ­ Parsed emotion: prefix='{emotion_prefix}', tag='{emotion_tag}'")
    
    return emotion_tag, clean_text


def _parse_emotion_from_prefix(emotion_prefix: str) -> Optional[str]:
    """
    Parse emotion tag from emotion prefix string.
    
    æ ¹æ®è¯­æ°”å‰ç¼€å†…å®¹åˆ¤æ–­æƒ…ç»ªæ ‡ç­¾ã€‚
    
    Args:
        emotion_prefix: The emotion prefix like "ï¼ˆè¯­æ°”ï¼šå¼€å¿ƒã€è½»å¿«ï¼Œè¯­é€Ÿç¨å¿«ï¼‰"
        
    Returns:
        Emotion tag string or None if no matching emotion found
    """
    # Check for each keyword in priority order
    # Priority: angry > crying > sad > excited > happy > gentle
    priority_order = ["angry", "crying", "sad", "excited", "happy", "gentle"]
    
    for target_emotion in priority_order:
        for keyword, emotion in EMOTION_KEYWORDS_MAP.items():
            if emotion == target_emotion and keyword in emotion_prefix:
                return emotion
    
    return None


def strip_emotion_prefix(response: str) -> str:
    """
    Strip emotion prefix from response, returning only clean text.
    
    ä»…å»é™¤è¯­æ°”å‰ç¼€ï¼Œè¿”å›å¹²å‡€æ–‡æœ¬ã€‚
    
    Args:
        response: The full LLM response that may contain emotion prefix
        
    Returns:
        Clean text with emotion prefix stripped
    """
    _, clean_text = extract_emotion_and_text(response)
    return clean_text


# Multi-message split marker
MSG_SPLIT_MARKER = "[MSG_SPLIT]"


def parse_multi_message_response(response: str) -> Tuple[list, str]:
    """
    Parse LLM response to extract multiple messages if split markers are present.
    
    è§£æLLMå“åº”ï¼Œæå–å¤šæ¡æ¶ˆæ¯ï¼ˆå¦‚æœå­˜åœ¨åˆ†éš”æ ‡è®°ï¼‰ã€‚
    
    The LLM may include [MSG_SPLIT] markers to indicate where the response should
    be split into multiple Telegram messages. This function extracts each message
    while also returning the full content for storage/history purposes.
    
    Args:
        response: The LLM response that may contain [MSG_SPLIT] markers
        
    Returns:
        Tuple of (messages_list, full_content) where:
        - messages_list: List of individual message strings to send separately
        - full_content: The complete response without split markers (for storage)
        
    Examples:
        >>> parse_multi_message_response("ä½ å¥½å•Š[MSG_SPLIT]æœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿ")
        (["ä½ å¥½å•Š", "æœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿ"], "ä½ å¥½å•Š\næœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿ")
        
        >>> parse_multi_message_response("æ™®é€šå›å¤å†…å®¹")
        (["æ™®é€šå›å¤å†…å®¹"], "æ™®é€šå›å¤å†…å®¹")
    """
    if not response:
        return [], ""
    
    # Check if the response contains split markers
    if MSG_SPLIT_MARKER not in response:
        return [response.strip()], response.strip()
    
    # Split the response by the marker
    parts = response.split(MSG_SPLIT_MARKER)
    
    # Clean up each part and filter out empty strings
    messages = [part.strip() for part in parts if part.strip()]
    
    # Limit to maximum 3 messages to avoid spam
    if len(messages) > 3:
        logger.warning(f"ğŸ“ Multi-message response exceeded limit, truncating from {len(messages)} to 3 messages")
        messages = messages[:3]
    
    # Create full content by joining with newlines (for storage/history)
    full_content = "\n".join(messages)
    
    logger.info(f"ğŸ“ Parsed multi-message response: {len(messages)} message(s)")
    
    return messages, full_content
