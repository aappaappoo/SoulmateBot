"""
History Filter Utility - å¯¹è¯å†å²è¿‡æ»¤å·¥å…·

æä¾›å¯¹è¯å†å²çš„è¿‡æ»¤åŠŸèƒ½ï¼š
1. è¿‡æ»¤URLé“¾æ¥
2. è¿‡æ»¤ä¸é‡è¦çš„å¯¹è¯å†…å®¹
3. å°†è¿‡æ»¤çš„å†…å®¹å­˜å‚¨åˆ°ç£ç›˜ä¾›åç»­æ£€ç´¢

ç”¨äºä¼˜åŒ–tokenä½¿ç”¨ï¼Œå‡å°‘å‘é€ç»™LLMçš„å†å²å¯¹è¯å†…å®¹
"""
import re
import os
import json
import hashlib
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field, asdict
from datetime import datetime, timezone
from pathlib import Path
from loguru import logger


@dataclass
class FilteredContent:
    """è¢«è¿‡æ»¤çš„å†…å®¹è®°å½•"""
    original_content: str
    filter_reason: str  # "url", "repetitive", "trivial"
    extracted_urls: List[str] = field(default_factory=list)
    timestamp: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
    placeholder: str = ""  # ç”¨äºæ›¿æ¢åŸå†…å®¹çš„å ä½ç¬¦


@dataclass 
class FilterResult:
    """è¿‡æ»¤ç»“æœ"""
    filtered_history: List[Dict[str, str]]  # è¿‡æ»¤åçš„å¯¹è¯å†å²
    filtered_out: List[FilteredContent]  # è¢«è¿‡æ»¤çš„å†…å®¹
    storage_path: Optional[str] = None  # å­˜å‚¨è·¯å¾„


class HistoryFilter:
    """
    å¯¹è¯å†å²è¿‡æ»¤å™¨
    
    åŠŸèƒ½ï¼š
    1. æ£€æµ‹å¹¶è¿‡æ»¤URLé“¾æ¥
    2. æ£€æµ‹å¹¶è¿‡æ»¤ç®€å•å¯’æš„ï¼ˆå¦‚"å¥½çš„"ã€"è°¢è°¢"ç­‰ï¼‰
    3. æ£€æµ‹å¹¶è¿‡æ»¤é‡å¤å†…å®¹
    4. å°†è¿‡æ»¤å†…å®¹å­˜å‚¨åˆ°ç£ç›˜
    """
    
    # URLæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ - ä½¿ç”¨éæ•è·ç»„é¿å…ç©ºåŒ¹é…
    URL_PATTERN = re.compile(
        r'(?:https?://[^\s<>"{}|\\^`\[\]]+)|'  # http/https URLs
        r'(?:www\.[^\s<>"{}|\\^`\[\]]+)|'       # www URLs
        r'(?:[a-zA-Z0-9.-]+\.(?:com|org|net|io|cn|co|info|edu|gov|app|dev)[^\s]*)'  # Domain-like patterns
    )
    
    # ç®€å•å¯’æš„å…³é”®è¯ï¼ˆå®Œå…¨åŒ¹é…æˆ–ä¸»è¦å†…å®¹ä¸ºè¿™äº›ï¼‰
    TRIVIAL_PATTERNS = [
        r'^å¥½çš„[ã€‚ï¼]?$',
        r'^å¥½[ã€‚ï¼]?$',
        r'^å—¯[ã€‚ï¼]?$',
        r'^å—¯å—¯[ã€‚ï¼]?$',
        r'^å“¦[ã€‚ï¼]?$',
        r'^å“¦å“¦[ã€‚ï¼]?$',
        r'^è°¢è°¢[ã€‚ï¼]?$',
        r'^è°¢è°¢[ä½ æ‚¨][ã€‚ï¼]?$',
        r'^æ„Ÿè°¢[ã€‚ï¼]?$',
        r'^æ”¶åˆ°[ã€‚ï¼]?$',
        r'^æ˜ç™½[ã€‚ï¼]?$',
        r'^çŸ¥é“äº†[ã€‚ï¼]?$',
        r'^äº†è§£[ã€‚ï¼]?$',
        r'^è¡Œ[ã€‚ï¼]?$',
        r'^å¯ä»¥[ã€‚ï¼]?$',
        r'^æ²¡é—®é¢˜[ã€‚ï¼]?$',
        r'^OK[ã€‚ï¼]?$',
        r'^ok[ã€‚ï¼]?$',
    ]
    
    def __init__(
        self, 
        storage_dir: str = "data/filtered_history",
        enable_url_filter: bool = True,
        enable_trivial_filter: bool = True,
        enable_disk_storage: bool = True,
        min_content_length: int = 5,  # ä½äºæ­¤é•¿åº¦çš„å†…å®¹å¯èƒ½è¢«è§†ä¸ºä¸é‡è¦
        url_content_threshold: float = 0.7  # URLå å†…å®¹æ¯”ä¾‹è¶…è¿‡æ­¤å€¼æ—¶è¿‡æ»¤
    ):
        """
        åˆå§‹åŒ–è¿‡æ»¤å™¨
        
        Args:
            storage_dir: è¿‡æ»¤å†…å®¹å­˜å‚¨ç›®å½•
            enable_url_filter: æ˜¯å¦å¯ç”¨URLè¿‡æ»¤
            enable_trivial_filter: æ˜¯å¦å¯ç”¨ç®€å•å¯’æš„è¿‡æ»¤
            enable_disk_storage: æ˜¯å¦å¯ç”¨ç£ç›˜å­˜å‚¨
            min_content_length: æœ€å°å†…å®¹é•¿åº¦é˜ˆå€¼
            url_content_threshold: URLå æ¯”é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼æ—¶è¿‡æ»¤
        """
        self.storage_dir = Path(storage_dir)
        self.enable_url_filter = enable_url_filter
        self.enable_trivial_filter = enable_trivial_filter
        self.enable_disk_storage = enable_disk_storage
        self.min_content_length = min_content_length
        self.url_content_threshold = url_content_threshold
        
        # é¢„ç¼–è¯‘ç®€å•å¯’æš„æ¨¡å¼
        self._trivial_compiled = [re.compile(p, re.IGNORECASE) for p in self.TRIVIAL_PATTERNS]
        
        # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
        if enable_disk_storage:
            self.storage_dir.mkdir(parents=True, exist_ok=True)
    
    def filter_history(
        self,
        conversation_history: List[Dict[str, str]],
        chat_id: Optional[str] = None,
        user_id: Optional[str] = None
    ) -> FilterResult:
        """
        è¿‡æ»¤å¯¹è¯å†å²
        
        Args:
            conversation_history: åŸå§‹å¯¹è¯å†å²
            chat_id: å¯¹è¯IDï¼ˆç”¨äºå­˜å‚¨ï¼‰
            user_id: ç”¨æˆ·IDï¼ˆç”¨äºå­˜å‚¨ï¼‰
            
        Returns:
            FilterResult: è¿‡æ»¤ç»“æœ
        """
        filtered_history = []
        filtered_out = []
        
        for msg in conversation_history:
            content = msg.get("content", "")
            role = msg.get("role", "user")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿‡æ»¤
            should_filter, filter_reason, extracted_data = self._should_filter(content, role)
            
            if should_filter:
                # åˆ›å»ºè¿‡æ»¤è®°å½•
                filtered_content = FilteredContent(
                    original_content=content,
                    filter_reason=filter_reason,
                    extracted_urls=extracted_data.get("urls", []),
                    placeholder=self._generate_placeholder(filter_reason, extracted_data)
                )
                filtered_out.append(filtered_content)
                
                # å¦‚æœæœ‰å ä½ç¬¦ï¼Œç”¨å ä½ç¬¦æ›¿æ¢åŸå†…å®¹
                if filtered_content.placeholder:
                    filtered_history.append({
                        "role": role,
                        "content": filtered_content.placeholder
                    })
                # å¦åˆ™å®Œå…¨è¿‡æ»¤ï¼ˆä¸æ·»åŠ åˆ°å†å²ï¼‰
            else:
                # å¯¹äºæœªå®Œå…¨è¿‡æ»¤çš„å†…å®¹ï¼Œå¯èƒ½éœ€è¦æ¸…ç†URLä½†ä¿ç•™å…¶ä»–å†…å®¹
                cleaned_content = content
                if self.enable_url_filter:
                    cleaned_content = self._clean_urls_from_content(content)
                
                filtered_history.append({
                    "role": role,
                    "content": cleaned_content if cleaned_content.strip() else content
                })
        
        # å­˜å‚¨è¿‡æ»¤çš„å†…å®¹åˆ°ç£ç›˜
        storage_path = None
        if self.enable_disk_storage and filtered_out:
            storage_path = self._store_filtered_content(
                filtered_out, chat_id, user_id
            )
        
        logger.info(
            f"ğŸ“ [HistoryFilter] Filtered {len(filtered_out)} messages from "
            f"{len(conversation_history)} total. Remaining: {len(filtered_history)}"
        )
        
        return FilterResult(
            filtered_history=filtered_history,
            filtered_out=filtered_out,
            storage_path=storage_path
        )
    
    def _should_filter(
        self, 
        content: str, 
        role: str
    ) -> Tuple[bool, str, Dict[str, Any]]:
        """
        åˆ¤æ–­å†…å®¹æ˜¯å¦åº”è¯¥è¢«è¿‡æ»¤
        
        Returns:
            (should_filter, reason, extracted_data)
        """
        if not content or not content.strip():
            return True, "empty", {}
        
        content_stripped = content.strip()
        
        # 1. æ£€æŸ¥ç®€å•å¯’æš„ï¼ˆä»…å¯¹çŸ­å†…å®¹ï¼‰
        if self.enable_trivial_filter and len(content_stripped) <= 20:
            for pattern in self._trivial_compiled:
                if pattern.match(content_stripped):
                    return True, "trivial", {}
        
        # 2. æ£€æŸ¥URLå æ¯”
        if self.enable_url_filter:
            urls = self.URL_PATTERN.findall(content)
            if urls:
                # è®¡ç®—URLåœ¨å†…å®¹ä¸­çš„å æ¯”
                url_total_length = sum(len(url) for url in urls)
                content_length = len(content_stripped)
                
                if content_length > 0:
                    url_ratio = url_total_length / content_length
                    
                    # å¦‚æœURLå æ¯”è¶…è¿‡é˜ˆå€¼ï¼Œè¿‡æ»¤è¯¥æ¶ˆæ¯
                    if url_ratio >= self.url_content_threshold:
                        return True, "url_dominated", {"urls": urls}
        
        # 3. æ£€æŸ¥å†…å®¹é•¿åº¦ï¼ˆéå¸¸çŸ­çš„å†…å®¹å¯èƒ½ä¸é‡è¦ï¼‰
        if len(content_stripped) < self.min_content_length:
            # ä½†ä¸è¿‡æ»¤åŠ©æ‰‹çš„å›å¤
            if role == "user":
                return True, "too_short", {}
        
        return False, "", {}
    
    def _generate_placeholder(
        self, 
        filter_reason: str, 
        extracted_data: Dict[str, Any]
    ) -> str:
        """
        ç”Ÿæˆå ä½ç¬¦æ–‡æœ¬
        
        å¯¹äºæŸäº›è¿‡æ»¤çš„å†…å®¹ï¼Œç”Ÿæˆç®€çŸ­çš„å ä½ç¬¦è€Œä¸æ˜¯å®Œå…¨åˆ é™¤
        """
        if filter_reason == "url_dominated":
            urls = extracted_data.get("urls", [])
            if urls:
                return f"[ç”¨æˆ·åˆ†äº«äº†{len(urls)}ä¸ªé“¾æ¥]"
        elif filter_reason == "trivial":
            return ""  # ç®€å•å¯’æš„å®Œå…¨åˆ é™¤
        elif filter_reason == "too_short":
            return ""  # å¤ªçŸ­çš„å†…å®¹å®Œå…¨åˆ é™¤
        elif filter_reason == "empty":
            return ""
        
        return ""
    
    def _clean_urls_from_content(self, content: str) -> str:
        """
        ä»å†…å®¹ä¸­æ¸…ç†URLï¼Œä½†ä¿ç•™å…¶ä»–æ–‡æœ¬
        
        å¯¹äºURLå æ¯”ä¸é«˜çš„å†…å®¹ï¼Œåªæ¸…ç†URLéƒ¨åˆ†
        """
        cleaned = self.URL_PATTERN.sub("[é“¾æ¥]", content)
        return cleaned
    
    def _store_filtered_content(
        self,
        filtered_out: List[FilteredContent],
        chat_id: Optional[str],
        user_id: Optional[str]
    ) -> Optional[str]:
        """
        å°†è¿‡æ»¤çš„å†…å®¹å­˜å‚¨åˆ°ç£ç›˜
        
        Returns:
            å­˜å‚¨æ–‡ä»¶è·¯å¾„
        """
        try:
            # ç”Ÿæˆæ–‡ä»¶å - ä½¿ç”¨å•ä¸€æ—¶é—´æˆ³ç¡®ä¿ä¸€è‡´æ€§
            current_time = datetime.now(timezone.utc)
            timestamp = current_time.strftime("%Y%m%d_%H%M%S")
            identifier = f"{chat_id or 'unknown'}_{user_id or 'unknown'}"
            hash_suffix = hashlib.md5(identifier.encode()).hexdigest()[:8]
            filename = f"filtered_{timestamp}_{hash_suffix}.json"
            
            filepath = self.storage_dir / filename
            
            # å‡†å¤‡å­˜å‚¨æ•°æ®
            storage_data = {
                "chat_id": chat_id,
                "user_id": user_id,
                "timestamp": current_time.isoformat(),
                "filtered_count": len(filtered_out),
                "items": [asdict(item) for item in filtered_out]
            }
            
            # å†™å…¥æ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(storage_data, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"ğŸ“ [HistoryFilter] Stored filtered content to: {filepath}")
            return str(filepath)
            
        except Exception as e:
            logger.warning(f"âš ï¸ [HistoryFilter] Failed to store filtered content: {e}")
            return None
    
    def retrieve_filtered_content(
        self,
        chat_id: Optional[str] = None,
        user_id: Optional[str] = None,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        æ£€ç´¢ä¹‹å‰è¿‡æ»¤çš„å†…å®¹
        
        Args:
            chat_id: å¯¹è¯IDè¿‡æ»¤æ¡ä»¶
            user_id: ç”¨æˆ·IDè¿‡æ»¤æ¡ä»¶
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            è¿‡æ»¤å†…å®¹è®°å½•åˆ—è¡¨
        """
        if not self.storage_dir.exists():
            return []
        
        results = []
        
        try:
            # è·å–æ‰€æœ‰å­˜å‚¨æ–‡ä»¶ï¼ŒæŒ‰æ—¶é—´å€’åº
            files = sorted(
                self.storage_dir.glob("filtered_*.json"),
                key=lambda x: x.stat().st_mtime,
                reverse=True
            )
            
            for filepath in files[:limit * 2]:  # å¤šè¯»ä¸€äº›ä»¥ä¾¿è¿‡æ»¤
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # æ£€æŸ¥è¿‡æ»¤æ¡ä»¶
                    if chat_id and data.get("chat_id") != chat_id:
                        continue
                    if user_id and data.get("user_id") != user_id:
                        continue
                    
                    results.append(data)
                    
                    if len(results) >= limit:
                        break
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to read filtered content file {filepath}: {e}")
                    continue
            
        except Exception as e:
            logger.warning(f"âš ï¸ [HistoryFilter] Failed to retrieve filtered content: {e}")
        
        return results
    
    def extract_urls(self, content: str) -> List[str]:
        """
        ä»å†…å®¹ä¸­æå–æ‰€æœ‰URL
        
        Args:
            content: æ–‡æœ¬å†…å®¹
            
        Returns:
            URLåˆ—è¡¨
        """
        return self.URL_PATTERN.findall(content)
    
    def is_url_dominated(self, content: str) -> bool:
        """
        æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸»è¦ç”±URLç»„æˆ
        
        Args:
            content: æ–‡æœ¬å†…å®¹
            
        Returns:
            æ˜¯å¦URLä¸»å¯¼
        """
        if not content or not content.strip():
            return False
        
        urls = self.extract_urls(content)
        if not urls:
            return False
        
        url_length = sum(len(url) for url in urls)
        return url_length / len(content.strip()) >= self.url_content_threshold


# å…¨å±€è¿‡æ»¤å™¨å®ä¾‹
_history_filter: Optional[HistoryFilter] = None


def get_history_filter() -> HistoryFilter:
    """è·å–å…¨å±€å†å²è¿‡æ»¤å™¨å®ä¾‹"""
    global _history_filter
    
    if _history_filter is None:
        _history_filter = HistoryFilter()
    
    return _history_filter
