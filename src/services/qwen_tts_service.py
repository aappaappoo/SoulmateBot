"""
Text-to-Speech (TTS) service for voice response generation
"""
import io
import os
import base64
import threading
import time
import asyncio
from typing import Optional
from datetime import datetime
from pathlib import Path
from loguru import logger
import subprocess
import tempfile
import re
import numpy as np
from config import settings


try:
    import dashscope
    from dashscope.audio.qwen_tts_realtime import QwenTtsRealtime, QwenTtsRealtimeCallback, AudioFormat

    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False
    logger.warning("dashscope package not installed. Qwen TTS will not be available.")


# åœ¨ qwen_tts_service.py é¡¶éƒ¨æ·»åŠ 
_EMOTION_PATTERN = re.compile(r'^ï¼ˆè¯­æ°”ï¼š([^ï¼‰]+)ï¼‰')


def extract_emotion_and_text(text: str) -> str | None:
    """ç®€å•æå–æƒ…æ„Ÿå‰ç¼€ç”¨äºæ—¥å¿—ï¼ˆé¿å…å¾ªç¯å¯¼å…¥ï¼‰"""
    match = _EMOTION_PATTERN.match(text)
    return match.group(1) if match else None



class QwenTTSCallback(QwenTtsRealtimeCallback):
    """
    Qwen TTS å›è°ƒå¤„ç†å™¨
    ç”¨äºæ¥æ”¶å’Œå¤„ç† TTS ç”Ÿæˆçš„éŸ³é¢‘æ•°æ®
    """

    def __init__(self):
        self.complete_event = threading.Event()
        self.audio_buffer = bytearray()
        self.session_id = None
        self.first_audio_delay = None
        self.error_message = None
        self._start_time = None

    def on_open(self) -> None:
        logger.debug("Qwen TTS WebSocket connection opened")
        self._start_time = time.time()

    def on_close(self, close_status_code, close_msg) -> None:
        logger.debug(f"Qwen TTS WebSocket connection closed: {close_status_code}, {close_msg}")

    def on_event(self, response: dict) -> None:
        try:
            msg_type = response.get('type')

            if msg_type == 'session.created':
                self.session_id = response.get('session', {}).get('id')
                logger.debug(f"Qwen TTS session created: {self.session_id}")

            elif msg_type == 'response.audio.delta':
                # é¦–æ¬¡æ”¶åˆ°éŸ³é¢‘æ•°æ®æ—¶è®°å½•å»¶è¿Ÿ
                if self.first_audio_delay is None and self._start_time:
                    self.first_audio_delay = time.time() - self._start_time
                    logger.debug(f"Qwen TTS first audio delay: {self.first_audio_delay:.3f}s")

                recv_audio_b64 = response.get('delta', '')
                if recv_audio_b64:
                    pcm_bytes = base64.b64decode(recv_audio_b64)
                    self.audio_buffer.extend(pcm_bytes)

            elif msg_type == 'response.done':
                logger.debug("Qwen TTS response done")

            elif msg_type == 'session.finished':
                logger.debug("Qwen TTS session finished")
                self.complete_event.set()

            elif msg_type == 'error':
                self.error_message = response.get('message', 'Unknown error')
                logger.error(f"Qwen TTS error: {self.error_message}")
                self.complete_event.set()

        except Exception as e:
            logger.error(f"Qwen TTS callback error: {e}")
            self.error_message = str(e)
            self.complete_event.set()

    def wait_for_finished(self, timeout: float = 60.0) -> bool:
        """
        ç­‰å¾… TTS å®Œæˆ
        
        Args:
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            True å¦‚æœæˆåŠŸå®Œæˆï¼ŒFalse å¦‚æœè¶…æ—¶
        """
        return self.complete_event.wait(timeout=timeout)

    def get_audio_bytes(self) -> bytes:
        """
        è·å–ç”Ÿæˆçš„ PCM éŸ³é¢‘æ•°æ®
        
        Returns:
            PCM æ ¼å¼çš„éŸ³é¢‘å­—èŠ‚æ•°æ®
        """
        return bytes(self.audio_buffer)

    def get_audio_numpy(self) -> np.ndarray:
        """
        è·å– numpy æ ¼å¼çš„éŸ³é¢‘æ•°æ®
        PCM_16BIT -> float32 numpy (-1 ~ 1)
        
        Returns:
            numpy æ•°ç»„æ ¼å¼çš„éŸ³é¢‘æ•°æ®
        """
        pcm = np.frombuffer(self.audio_buffer, dtype=np.int16)
        audio = pcm.astype(np.float32) / 32768.0
        return audio


class QwenTTSService:
    """
    Qwen Text-to-Speech æœåŠ¡
    ä½¿ç”¨é˜¿é‡Œäº‘ DashScope çš„ Qwen TTS Realtime API
    """

    # Qwen TTS å¯ç”¨éŸ³è‰²åˆ—è¡¨
    # voice å‚æ•°    è¯´æ˜                             é€‚ç”¨
    # Cherry      é˜³å…‰ç§¯æã€äº²åˆ‡è‡ªç„¶çš„å¥³æ€§éŸ³è‰²         Realtime & Flash
    # Serena      æ¸©æŸ”çš„å¥³æ€§éŸ³è‰²                      Realtime & Flashï¼ˆéƒ¨åˆ†æ¨¡å‹ï¼‰
    # Ethan       é˜³å…‰ã€æ¸©æš–ã€æ´»åŠ›çš„ç”·æ€§éŸ³è‰²           Realtime & Flashï¼ˆéƒ¨åˆ†æ¨¡å‹ï¼‰
    # Chelsie     è™šæ‹Ÿé£æ ¼å¥³ç”Ÿ                        æ ‡å‡† TTSï¼ˆéƒ¨åˆ†ç‰ˆæœ¬ï¼‰
    # Dylan       åŒ—äº¬è¯é£æ ¼ç”·å£°                      æ ‡å‡† TTSï¼ˆéƒ¨åˆ†ç‰ˆæœ¬ï¼‰
    # Jada        ä¸Šæµ·è¯é£æ ¼å¥³å£°                      æ ‡å‡† TTSï¼ˆéƒ¨åˆ†ç‰ˆæœ¬ï¼‰
    # Sunny       å››å·è¯å¥³å£°                          æ ‡å‡† TTSï¼ˆéƒ¨åˆ†ç‰ˆæœ¬ï¼‰
    AVAILABLE_VOICES = {
        "Cherry": {"description": "é˜³å…‰ç§¯æã€äº²åˆ‡è‡ªç„¶çš„å¥³æ€§éŸ³è‰²", "type": "realtime"},
        "Serena": {"description": "æ¸©æŸ”çš„å¥³æ€§éŸ³è‰²", "type": "realtime"},
        "Ethan": {"description": "é˜³å…‰ã€æ¸©æš–ã€æ´»åŠ›çš„ç”·æ€§éŸ³è‰²", "type": "realtime"},
        "Chelsie": {"description": "è™šæ‹Ÿé£æ ¼å¥³ç”Ÿ", "type": "standard"},
        "Dylan": {"description": "åŒ—äº¬è¯é£æ ¼ç”·å£°", "type": "standard"},
        "Jada": {"description": "ä¸Šæµ·è¯é£æ ¼å¥³å£°", "type": "standard"},
        "Sunny": {"description": "å››å·è¯å¥³å£°", "type": "standard"},
    }

    # æƒ…æ„Ÿæ˜ å°„
    EMOTION_MAP = {
        "happy": "ï¼ˆè¯­æ°”ï¼šå¼€å¿ƒã€è½»å¿«ã€å…´å¥‹ï¼Œè¯­é€Ÿç¨å¿«ï¼Œè¯­è°ƒä¸Šæ‰¬ï¼‰",
        "gentle": "ï¼ˆè¯­æ°”ï¼šæ¸©æŸ”ã€è½»å£°ã€æ”¾æ…¢è¯­é€Ÿï¼Œè¯­è°ƒæŸ”å’Œï¼‰",
        "sad": "ï¼ˆè¯­æ°”ï¼šä½è½ã€è¯­é€Ÿè¾ƒæ…¢ï¼Œæƒ…ç»ªå…‹åˆ¶ï¼‰",
        "excited": "ï¼ˆè¯­æ°”ï¼šéå¸¸å…´å¥‹ï¼ŒèŠ‚å¥æ´»è·ƒï¼Œå¯Œæœ‰æ„ŸæŸ“åŠ›ï¼‰",
        "angry": "ï¼ˆè¯­æ°”ï¼šç”Ÿæ°”ï¼Œæ„¤æ€’ï¼‰",
        "crying": "ï¼ˆå§”å±ˆï¼Œå“­æ³£ï¼‰",
    }

    # WebSocket API URL
    DEFAULT_API_URL = "wss://dashscope.aliyuncs.com/api-ws/v1/realtime"

    # é»˜è®¤é‡‡æ ·ç‡
    SAMPLE_RATE = 24000

    def __init__(self):
        self.voice_dir = Path("data/voice")
        self.voice_dir.mkdir(parents=True, exist_ok=True)
        self.default_voice = getattr(settings, 'default_qwen_voice_id', 'Cherry')
        self.api_key = getattr(settings, 'dashscope_api_key', None)
        self.api_url = getattr(settings, 'dashscope_api_url', self.DEFAULT_API_URL)
        self.model = getattr(settings, 'qwen_tts_model', 'qwen3-tts-flash-realtime')
        self.speed = getattr(settings, 'qwen_tts_speed', 1.0)

        # ä»ç¯å¢ƒå˜é‡è·å– API keyï¼ˆå¦‚æœæœªåœ¨é…ç½®ä¸­è®¾ç½®ï¼‰
        if not self.api_key and 'DASHSCOPE_API_KEY' in os.environ:
            self.api_key = os.environ['DASHSCOPE_API_KEY']

    def _get_qwen_voice_id(self, voice_id: Optional[str]) -> str:
        """
        è·å– Qwen éŸ³è‰² ID
        
        å¦‚æœä¼ å…¥çš„éŸ³è‰²æœ‰æ•ˆï¼Œåˆ™ç›´æ¥è¿”å›
        å¦åˆ™è¿”å›é»˜è®¤éŸ³è‰²
        """
        if not voice_id:
            return self.default_voice

        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ Qwen éŸ³è‰²
        if voice_id in self.AVAILABLE_VOICES:
            return voice_id

        # å°è¯•åŒ¹é…ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
        for v in self.AVAILABLE_VOICES:
            if v.lower() == voice_id.lower():
                return v

        logger.warning(f"Invalid Qwen voice_id '{voice_id}', using default: {self.default_voice}")
        return self.default_voice

    async def generate_voice(
            self,
            text: str,
            voice_id: Optional[str] = None,
            user_id: Optional[int] = None,
            emotion: Optional[str] = None
    ) -> Optional[bytes]:
        """
        å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬å†…å®¹
            voice_id: è¯­éŸ³éŸ³è‰² ID
            user_id: ç”¨æˆ· IDï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
            emotion: æƒ…æ„Ÿæ ‡ç­¾ï¼ˆå¯é€‰ï¼Œå¦‚ happy, gentle, sad, excitedï¼‰
            
        Returns:
            è¯­éŸ³æ•°æ®çš„å­—èŠ‚æµï¼ˆPCM æ ¼å¼ï¼‰ï¼Œå¦‚æœå¤±è´¥è¿”å› None
        """
        logger.info(
            f"ğŸ”Š [TTS QWEN] generate_voice called: voice_id={voice_id}, text_length={len(text)}, user_id={user_id}")

        if not DASHSCOPE_AVAILABLE:
            logger.error("ğŸ”Š [TTS QWEN] dashscope package not installed, cannot generate voice")
            return None

        if not self.api_key:
            logger.error("ğŸ”Š [TTS QWEN] DashScope API key not configured, cannot generate voice")
            return None

        # è·å– Qwen éŸ³è‰² ID
        qwen_voice = self._get_qwen_voice_id(voice_id)
        logger.info(f"ğŸ”Š [TTS QWEN] Resolved voice_id: input={voice_id} -> qwen_voice={qwen_voice}")

        try:
            logger.info(f"ğŸ”Š [TTS QWEN] Starting WebSocket connection to Qwen TTS API")
            # ä½¿ç”¨åŒæ­¥ WebSocket å¹¶åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ
            audio_data = await asyncio.get_event_loop().run_in_executor(
                None,
                self._sync_generate_voice,
                text,
                qwen_voice,
                emotion
            )

            if audio_data:
                logger.info(f"ğŸ”Š [TTS QWEN] Voice generated successfully: audio_size={len(audio_data)} bytes")
            else:
                logger.warning(f"ğŸ”Š [TTS QWEN] Voice generation returned no data")

            return audio_data

        except Exception as e:
            logger.error(f"ğŸ”Š [TTS QWEN] TTS generation error: {str(e)}", exc_info=True)
            return None

    def _sync_generate_voice(
            self,
            text: str,
            voice_id: str,
            emotion: Optional[str] = None
    ) -> Optional[bytes]:
        """
        åŒæ­¥æ–¹å¼ç”Ÿæˆè¯­éŸ³ï¼ˆç”¨äºåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰
        """
        callback = QwenTTSCallback()
        qwen_tts_realtime = None

        try:
            if self.api_key:
                dashscope.api_key = self.api_key

            # åˆ›å»º TTS å®¢æˆ·ç«¯ï¼Œä¼ å…¥ API key
            qwen_tts_realtime = QwenTtsRealtime(
                model=self.model,
                callback=callback,
                url=self.api_url,
            )

            # è¿æ¥
            qwen_tts_realtime.connect()
            # æ›´æ–°ä¼šè¯é…ç½®
            qwen_tts_realtime.update_session(
                voice=voice_id,
                response_format=AudioFormat.PCM_24000HZ_MONO_16BIT,
                mode='server_commit',
            )

            # å¦‚æœæœ‰æƒ…æ„Ÿæ ‡ç­¾ï¼Œæ·»åŠ æƒ…æ„Ÿæè¿°å‰ç¼€
            extracted_emotion = extract_emotion_and_text(text)
            if extracted_emotion:
                logger.debug(f"ğŸ”Š [TTS QWEN] Text contains emotion prefix: {extracted_emotion}")
            else:
                logger.debug(f"ğŸ”Š [TTS QWEN] Text contains emotion prefix: None")

            # è¿™ä¸ªéƒ¨åˆ†æš‚æ—¶å…ˆåˆ é™¤åç»­å¢åŠ æƒ…æ„Ÿéƒ¨åˆ†
            text = re.compile(r'^ï¼ˆè¯­æ°”ï¼š[^ï¼‰]+ï¼‰').sub('', text)
            qwen_tts_realtime.append_text(text)

            # å®Œæˆå‘é€
            qwen_tts_realtime.finish()

            # ç­‰å¾…å®Œæˆ
            if not callback.wait_for_finished(timeout=60.0):
                logger.error("ğŸ”Š [TTS QWEN] TTS generation timeout")
                return None

            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if callback.error_message:
                logger.error(f"ğŸ”Š [TTS QWEN] TTS generation failed: {callback.error_message}")
                return None

            # è·å–éŸ³é¢‘æ•°æ®
            audio_data = callback.get_audio_bytes()

            if not audio_data:
                logger.warning("ğŸ”Š [TTS QWEN] No audio data received from Qwen TTS")
                return None

            logger.info(f"ğŸ”Š [TTS QWEN] Metrics - session: {callback.session_id}, "
                        f"first_audio_delay: {callback.first_audio_delay:.3f}s" if callback.first_audio_delay else "")

            return audio_data

        except Exception as e:
            logger.error(f"ğŸ”Š [TTS QWEN] Error in sync voice generation: {e}", exc_info=True)
            return None
        finally:
            # ç¡®ä¿æ¸…ç†è¿æ¥èµ„æº
            if qwen_tts_realtime is not None:
                try:
                    # å°è¯•å…³é—­è¿æ¥
                    if hasattr(qwen_tts_realtime, 'close'):
                        qwen_tts_realtime.close()
                except Exception as cleanup_error:
                    logger.debug(f"ğŸ”Š [TTS QWEN] Cleanup error (ignored): {cleanup_error}")

    async def generate_voice_file(
            self,
            text: str,
            voice_id: Optional[str] = None,
            user_id: Optional[int] = None,
            emotion: Optional[str] = None
    ) -> Optional[str]:
        """
        å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶ä¿å­˜åˆ°æ–‡ä»¶
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬å†…å®¹
            voice_id: è¯­éŸ³éŸ³è‰² ID
            user_id: ç”¨æˆ· ID
            emotion: æƒ…æ„Ÿæ ‡ç­¾
            
        Returns:
            è¯­éŸ³æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å› None
        """
        audio_data = await self.generate_voice(text, voice_id, user_id, emotion)

        if audio_data is None:
            return None

        # ç”Ÿæˆæ–‡ä»¶åå¹¶ä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        user_suffix = f"_user_{user_id}" if user_id else ""
        filename = f"voice_{timestamp}{user_suffix}.pcm"
        filepath = self.voice_dir / filename

        try:
            with open(filepath, 'wb') as f:
                f.write(audio_data)

            logger.info(f"Voice file saved: {filepath}")
            return str(filepath)

        except Exception as e:
            logger.error(f"Failed to save voice file: {str(e)}")
            return None

    def get_voice_as_buffer(self, audio_data: bytes) -> io.BytesIO:
        """
        å°† PCM éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º Telegram æ”¯æŒçš„ OGG/Opus æ ¼å¼

        Args:
            audio_data: PCM æ ¼å¼çš„éŸ³é¢‘å­—èŠ‚æ•°æ® (24kHz, 16-bit, mono)

        Returns:
            BytesIO ç¼“å†²åŒºå¯¹è±¡ï¼ˆOGG/Opus æ ¼å¼ï¼‰
        """
        try:
            # ä½¿ç”¨ ffmpeg å°† PCM è½¬æ¢ä¸º OGG/Opus
            with tempfile.NamedTemporaryFile(suffix='.pcm', delete=False) as pcm_file:
                pcm_file.write(audio_data)
                pcm_path = pcm_file.name

            ogg_path = pcm_path.replace('.pcm', '.ogg')
            tempo_value = max(0.5, min(2.0, self.speed))  # é™åˆ¶åœ¨æœ‰æ•ˆèŒƒå›´å†…
            logger.info(f"ğŸ”Š [TTS QWEN] update_session with speed={self.speed}")
            cmd = [
                'ffmpeg', '-y',
                '-f', 's16le',
                '-ar', '24000',
                '-ac', '1',
                '-i', pcm_path,
                '-af', f'atempo={tempo_value}',  # æ·»åŠ è¯­é€Ÿè°ƒæ•´
                '-c:a', 'libopus',
                '-b:a', '32k',
                ogg_path
            ]

            subprocess.run(cmd, check=True, capture_output=True)

            # è¯»å–è½¬æ¢åçš„æ–‡ä»¶
            with open(ogg_path, 'rb') as f:
                ogg_data = f.read()

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            import os
            os.unlink(pcm_path)
            os.unlink(ogg_path)
            buffer = io.BytesIO(ogg_data)
            buffer.name = "voice.ogg"
            buffer.seek(0)

            logger.info(f"ğŸ”Š [TTS QWEN] Converted PCM to OGG/Opus: {len(audio_data)} -> {len(ogg_data)} bytes")
            return buffer

        except Exception as e:
            logger.error(f"ğŸ”Š [TTS QWEN] Failed to convert PCM to OGG: {e}")
            # å›é€€ï¼šè¿”å›åŸå§‹ PCMï¼ˆè™½ç„¶ Telegram ä¸æ”¯æŒï¼‰
            buffer = io.BytesIO(audio_data)
            buffer.name = "voice.pcm"
            buffer.seek(0)
            return buffer

    @staticmethod
    def is_voice_id_valid(voice_id: str) -> bool:
        """
        æ£€æŸ¥éŸ³è‰² ID æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            voice_id: è¦æ£€æŸ¥çš„éŸ³è‰² ID
            
        Returns:
            True å¦‚æœæœ‰æ•ˆï¼Œå¦åˆ™ False
        """
        if not voice_id:
            return False

        # æ£€æŸ¥æ˜¯å¦åœ¨å¯ç”¨éŸ³è‰²åˆ—è¡¨ä¸­ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
        return voice_id in QwenTTSService.AVAILABLE_VOICES or \
            voice_id.lower() in [v.lower() for v in QwenTTSService.AVAILABLE_VOICES]

    @staticmethod
    def get_available_voices() -> dict:
        """
        è·å–æ‰€æœ‰å¯ç”¨çš„éŸ³è‰²åˆ—è¡¨
        
        Returns:
            å¯ç”¨éŸ³è‰²å­—å…¸ï¼ŒåŒ…å«éŸ³è‰²è¯¦ç»†ä¿¡æ¯
        """
        return QwenTTSService.AVAILABLE_VOICES.copy()

    @staticmethod
    def get_voice_for_gender(gender: str, personality: str = "default") -> str:
        """
        æ ¹æ®æ€§åˆ«å’Œæ€§æ ¼æ¨èåˆé€‚çš„éŸ³è‰²
        
        Args:
            gender: æ€§åˆ«ï¼Œ"male" æˆ– "female"
            personality: æ€§æ ¼ç±»å‹ï¼Œå¦‚ "gentle", "lively", "mature" ç­‰
            
        Returns:
            æ¨èçš„éŸ³è‰² ID
        """
        if gender == "male":
            # ç”·æ€§éŸ³è‰²
            if personality in ["warm", "lively", "default"]:
                return "Ethan"  # é˜³å…‰ã€æ¸©æš–ã€æ´»åŠ›çš„ç”·æ€§éŸ³è‰²
            elif personality in ["mature", "calm"]:
                return "Dylan"  # åŒ—äº¬è¯é£æ ¼ç”·å£°
            else:
                return "Ethan"  # é»˜è®¤ç”·å£°
        else:  # female
            # å¥³æ€§éŸ³è‰²
            if personality in ["gentle", "warm"]:
                return "Serena"  # æ¸©æŸ”çš„å¥³æ€§éŸ³è‰²
            elif personality in ["lively", "cute", "default"]:
                return "Cherry"  # é˜³å…‰ç§¯æã€äº²åˆ‡è‡ªç„¶çš„å¥³æ€§éŸ³è‰²
            elif personality in ["virtual", "young"]:
                return "Chelsie"  # è™šæ‹Ÿé£æ ¼å¥³ç”Ÿ
            else:
                return "Cherry"  # é»˜è®¤å¥³å£°


# å…¨å±€ Qwen TTS æœåŠ¡å®ä¾‹
qwen_tts_service = QwenTTSService()
