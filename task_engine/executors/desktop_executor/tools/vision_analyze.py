"""
è§†è§‰åˆ†æå·¥å…· - VLM è¯†åˆ« UI å…ƒç´ åæ ‡

é€šè¿‡è§†è§‰è¯­è¨€æ¨¡å‹åˆ†ææˆªå›¾ï¼Œè¯†åˆ«æŒ‡å®š UI å…ƒç´ çš„ä½ç½®ã€‚
ä½¿ç”¨ vLLM çš„ OpenAI å…¼å®¹ APIï¼Œæ”¯æŒè§†è§‰æ¨¡å‹ï¼ˆå¦‚ Qwen-VL, LLaVA ç­‰ï¼‰ã€‚
"""
import base64
import json
import os
from typing import Optional

import aiohttp
from loguru import logger

from config import settings

# VLM é…ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨ VLM ä¸“ç”¨é…ç½®ï¼Œå›é€€åˆ° executor LLM é…ç½®ï¼‰
_VLM_URL = (
    getattr(settings, "vlm_api_url", None)
    or getattr(settings, "executor_llm_url", None)
    or "http://localhost:8000"
)
_VLM_MODEL = (
    getattr(settings, "vlm_model", None)
    or getattr(settings, "executor_llm_model", None)
    or "default"
)
_VLM_TOKEN = (
    getattr(settings, "vlm_api_token", None)
    or getattr(settings, "executor_llm_token", None)
    or ""
)

# VLM è§†è§‰åˆ†æ system prompt
_VISION_SYSTEM_PROMPT = (
    "ä½ æ˜¯ä¸€ä¸ªè§†è§‰ UI åˆ†æåŠ©æ‰‹ã€‚åˆ†æç»™å®šçš„å±å¹•æˆªå›¾ï¼Œæ‰¾åˆ°ç”¨æˆ·æè¿°çš„ UI å…ƒç´ ã€‚\n\n"
    "è¯·è¿”å› JSON æ ¼å¼çš„ç»“æœï¼š\n"
    "{\n"
    '  "found": true,\n'
    '  "elements": [\n'
    "    {\n"
    '      "description": "å…ƒç´ æè¿°",\n'
    '      "x": ä¸­å¿ƒXåæ ‡,\n'
    '      "y": ä¸­å¿ƒYåæ ‡,\n'
    '      "width": å…ƒç´ å®½åº¦,\n'
    '      "height": å…ƒç´ é«˜åº¦,\n'
    '      "confidence": ç½®ä¿¡åº¦\n'
    "    }\n"
    "  ]\n"
    "}\n\n"
    "æ³¨æ„ï¼š\n"
    "- åæ ‡ä¸ºæˆªå›¾ä¸­çš„åƒç´ åæ ‡ï¼ˆæ•´æ•°ï¼‰\n"
    "- å¦‚æœæ‰¾åˆ°å¤šä¸ªåŒ¹é…å…ƒç´ ï¼Œå…¨éƒ¨åˆ—å‡º\n"
    '- å¦‚æœæœªæ‰¾åˆ°ï¼Œè¿”å› {"found": false, "elements": []}\n'
    "- åªè¿”å› JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—"
)


def _encode_image(image_path: str) -> str:
    """å°†å›¾ç‰‡æ–‡ä»¶ç¼–ç ä¸º base64 å­—ç¬¦ä¸²"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")


def _get_mime_type(image_path: str) -> str:
    """æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å– MIME ç±»å‹"""
    ext = os.path.splitext(image_path)[1].lower()
    mime_map = {
        ".png": "image/png",
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".gif": "image/gif",
        ".webp": "image/webp",
        ".bmp": "image/bmp",
    }
    return mime_map.get(ext, "image/png")


def _parse_vlm_response(content: str, query: str) -> dict:
    """
    è§£æ VLM è¿”å›çš„å†…å®¹ä¸ºç»“æ„åŒ–ç»“æœ

    Args:
        content: VLM è¿”å›çš„æ–‡æœ¬å†…å®¹
        query: åŸå§‹æŸ¥è¯¢

    Returns:
        dict: ç»“æ„åŒ–çš„åˆ†æç»“æœ
    """
    content = content.strip()

    # å¤„ç† JSON è¢«ä»£ç å—åŒ…è£¹çš„æƒ…å†µ
    try:
        if "```json" in content:
            start = content.index("```json") + 7
            end = content.index("```", start)
            content = content[start:end].strip()
        elif "```" in content:
            start = content.index("```") + 3
            end = content.index("```", start)
            content = content[start:end].strip()
    except ValueError:
        pass  # ä»£ç å—æ ¼å¼ä¸å®Œæ•´ï¼Œä½¿ç”¨åŸå§‹å†…å®¹ç»§ç»­è§£æ

    try:
        parsed = json.loads(content)
        if isinstance(parsed, dict):
            found = parsed.get("found", False)
            elements = parsed.get("elements", [])
            valid_elements = []
            for elem in elements:
                if isinstance(elem, dict) and "x" in elem and "y" in elem:
                    valid_elements.append(
                        {
                            "description": elem.get("description", query),
                            "x": int(elem.get("x", 0)),
                            "y": int(elem.get("y", 0)),
                            "width": int(elem.get("width", 0)),
                            "height": int(elem.get("height", 0)),
                            "confidence": float(elem.get("confidence", 0.0)),
                        }
                    )
            return {
                "found": bool(found and valid_elements),
                "query": query,
                "elements": valid_elements,
            }
    except (json.JSONDecodeError, ValueError):
        pass

    # JSON è§£æå¤±è´¥æ—¶è¿”å›åŸå§‹å†…å®¹
    return {
        "found": False,
        "query": query,
        "message": content,
        "elements": [],
    }


async def vision_analyze(image_path: str, query: str) -> str:
    """
    ä½¿ç”¨è§†è§‰æ¨¡å‹åˆ†ææˆªå›¾ï¼Œè¯†åˆ« UI å…ƒç´ 

    Args:
        image_path: æˆªå›¾æ–‡ä»¶è·¯å¾„
        query: è¦æŸ¥æ‰¾çš„ UI å…ƒç´ æè¿°

    Returns:
        str: JSON æ ¼å¼çš„åˆ†æç»“æœï¼ŒåŒ…å«å…ƒç´ æè¿°å’Œåæ ‡
    """
    if not os.path.exists(image_path):
        return json.dumps({"error": f"æˆªå›¾æ–‡ä»¶ä¸å­˜åœ¨: {image_path}"}, ensure_ascii=False)

    # ç¼–ç å›¾ç‰‡ä¸º base64
    try:
        image_base64 = _encode_image(image_path)
    except Exception as e:
        return json.dumps({"error": f"å›¾ç‰‡è¯»å–å¤±è´¥: {e}"}, ensure_ascii=False)

    mime_type = _get_mime_type(image_path)

    # æ„å»º VLM è¯·æ±‚æ¶ˆæ¯ï¼ˆOpenAI å…¼å®¹çš„è§†è§‰æ ¼å¼ï¼‰
    messages = [
        {"role": "system", "content": _VISION_SYSTEM_PROMPT},
        {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:{mime_type};base64,{image_base64}",
                    },
                },
                {
                    "type": "text",
                    "text": f"è¯·åœ¨æˆªå›¾ä¸­æ‰¾åˆ°ä»¥ä¸‹ UI å…ƒç´ ï¼š{query}",
                },
            ],
        },
    ]

    # è°ƒç”¨ VLM API
    url = f"{_VLM_URL}/v1/chat/completions"
    payload = {
        "model": _VLM_MODEL,
        "messages": messages,
        "max_tokens": 1024,
        "temperature": 0.1,
    }
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {_VLM_TOKEN}",
    }

    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                url,
                json=payload,
                headers=headers,
                timeout=aiohttp.ClientTimeout(total=30),
            ) as resp:
                if resp.status != 200:
                    error_text = await resp.text()
                    logger.warning(f"VLM API è¿”å› {resp.status}: {error_text}")
                    return json.dumps(
                        {
                            "found": False,
                            "query": query,
                            "error": f"VLM API é”™è¯¯ (HTTP {resp.status})",
                            "elements": [],
                        },
                        ensure_ascii=False,
                    )
                data = await resp.json()
    except aiohttp.ClientError as e:
        logger.warning(f"VLM API è¿æ¥å¤±è´¥: {e}")
        return json.dumps(
            {
                "found": False,
                "query": query,
                "error": f"VLM æœåŠ¡è¿æ¥å¤±è´¥: {e}",
                "elements": [],
            },
            ensure_ascii=False,
        )
    except Exception as e:
        logger.warning(f"VLM è°ƒç”¨å¼‚å¸¸: {e}")
        return json.dumps(
            {
                "found": False,
                "query": query,
                "error": f"VLM è°ƒç”¨å¼‚å¸¸: {e}",
                "elements": [],
            },
            ensure_ascii=False,
        )

    # è§£æ VLM è¿”å›å†…å®¹
    try:
        content = data["choices"][0]["message"]["content"]
        logger.info(f"ğŸ‘ï¸ VLM åˆ†æå®Œæˆ: query={query}")
        result = _parse_vlm_response(content, query)
        return json.dumps(result, ensure_ascii=False)
    except (KeyError, IndexError) as e:
        logger.warning(f"VLM å“åº”æ ¼å¼å¼‚å¸¸: {e}, data={data}")
        return json.dumps(
            {
                "found": False,
                "query": query,
                "error": "VLM å“åº”æ ¼å¼å¼‚å¸¸",
                "elements": [],
            },
            ensure_ascii=False,
        )
