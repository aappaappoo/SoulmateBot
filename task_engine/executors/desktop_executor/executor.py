"""
æ¡Œé¢æ“æ§æ‰§è¡Œå™¨ - æ ¸å¿ƒ LLM tool-call å¾ªç¯

â­ è¿™æ˜¯æ•´ä¸ª task_engine ä¸­æœ€å…³é”®çš„æ¨¡å—ã€‚

æ‰§è¡Œæµç¨‹ï¼š
1. æ„å»º system promptï¼ˆæ¡Œé¢æ“æ§ç­–ç•¥ï¼‰
2. æ³¨å†Œ DesktopToolRegistry
3. while å¾ªç¯ï¼ˆmax 15 æ¬¡ï¼‰ï¼š
   - LLM è¿”å› tool_call
   - æ‰§è¡Œ tool
   - TaskGuard æ ¡éªŒ
   - å°† tool result å›å¡« messages
4. LLM ä¸å†è°ƒç”¨å·¥å…· â†’ ä»»åŠ¡å®Œæˆ

tool_call é€šè¿‡ aiohttp è°ƒ vLLM /v1/chat/completions
ï¼ˆVLLMProvider æœ¬èº«ä¸æ”¯æŒ toolsï¼‰
"""
import json
from typing import Any, Dict, List, Optional
from loguru import logger

from task_engine.models import Step, StepResult
from task_engine.executors.base import BaseExecutor
from task_engine.executors.desktop_executor.guard import GuardAction, TaskGuard
from task_engine.executors.desktop_executor.tools import TOOL_DEFINITIONS, TOOL_REGISTRY
from config import settings


# æ‰§è¡Œçš„LLMé…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
EXECUTOR_LLM_URL = getattr(settings, 'executor_llm_url', "http://localhost:8000")
EXECUTOR_LLM_MODEL = getattr(settings, 'executor_llm_model', "default")
EXECUTOR_LLM_TOKEN = getattr(settings, 'executor_llm_token', "")
_MAX_ITERATIONS = getattr(settings, 'max_iterations', "")



# æ¡Œé¢æ“æ§ system prompt
_SYSTEM_PROMPT: str = """ä½ æ˜¯ä¸€ä¸ªæ¡Œé¢æ“æ§åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯é€šè¿‡è°ƒç”¨å·¥å…·æ¥å®Œæˆç”¨æˆ·çš„æ¡Œé¢æ“ä½œè¯·æ±‚ã€‚

å¯ç”¨å·¥å…·ï¼š
- app_open: æ‰“å¼€æµè§ˆå™¨/URL
- screenshot: å±å¹•æˆªå›¾
- vision_analyze: è§†è§‰åˆ†ææˆªå›¾ï¼Œè¯†åˆ« UI å…ƒç´ åæ ‡
- click: é¼ æ ‡ç‚¹å‡»æŒ‡å®šåæ ‡
- type_text: åœ¨å½“å‰ç„¦ç‚¹ä½ç½®è¾“å…¥æ–‡æœ¬
- key_press: æŒ‰ä¸‹é”®ç›˜æŒ‰é”®
- shell_run: æ‰§è¡Œ shell å‘½ä»¤

æ“ä½œç­–ç•¥ï¼š
1. å…ˆæ‰“å¼€ç›®æ ‡åº”ç”¨/ç½‘é¡µ
2. æˆªå›¾æŸ¥çœ‹å½“å‰å±å¹•çŠ¶æ€
3. ç”¨è§†è§‰åˆ†ææ‰¾åˆ°ç›®æ ‡ UI å…ƒç´ 
4. ç‚¹å‡»/è¾“å…¥/æŒ‰é”®å®Œæˆæ“ä½œ
5. å†æ¬¡æˆªå›¾éªŒè¯ç»“æœ
6. é‡å¤ç›´åˆ°ä»»åŠ¡å®Œæˆ

æ³¨æ„äº‹é¡¹ï¼š
- ä¸è¦å°è¯•ç™»å½•ã€æ”¯ä»˜ã€è¾“å…¥å¯†ç ç­‰æ•æ„Ÿæ“ä½œ
- å¦‚æœæŸä¸ªç½‘ç«™éœ€è¦ç™»å½•æ‰èƒ½ä½¿ç”¨ï¼Œå°è¯•å…¶ä»–ç½‘ç«™
- æ¯æ¬¡æ“ä½œåéƒ½åº”æˆªå›¾ç¡®è®¤çŠ¶æ€
- ä»»åŠ¡å®Œæˆåï¼Œç”¨è‡ªç„¶è¯­è¨€æè¿°æ“ä½œç»“æœ
"""


class DesktopExecutor(BaseExecutor):
    """
    æ¡Œé¢æ“æ§æ‰§è¡Œå™¨

    é€šè¿‡ LLM tool-call å¾ªç¯å®ç°è‡ªä¸»æ¡Œé¢æ“æ§ã€‚
    """

    def __init__(self) -> None:
        self._guard = TaskGuard()

    async def execute(self, step: Step) -> StepResult:
        """
        æ‰§è¡Œæ¡Œé¢æ“æ§ä»»åŠ¡

        Args:
            step: åŒ…å« params["task"] çš„æ­¥éª¤

        Returns:
            StepResult: æ‰§è¡Œç»“æœ
        """
        task_text: str = step.params.get("task", "")
        if not task_text:
            return StepResult(success=False, message="ç¼ºå°‘ task å‚æ•°")

        self._guard.reset()

        # æ„å»ºåˆå§‹æ¶ˆæ¯
        messages: List[Dict[str, Any]] = [
            {"role": "system", "content": _SYSTEM_PROMPT},
            {"role": "user", "content": f"è¯·å®Œæˆä»¥ä¸‹æ¡Œé¢æ“ä½œä»»åŠ¡ï¼š{task_text}"},
        ]

        for iteration in range(1, _MAX_ITERATIONS + 1):
            # è°ƒç”¨ LLM è·å–ä¸‹ä¸€æ­¥æ“ä½œ
            llm_response = await self._call_llm(messages)

            if llm_response is None:
                return StepResult(
                    success=False,
                    message=f"LLM è°ƒç”¨å¤±è´¥ï¼ˆç¬¬ {iteration} è½®ï¼‰",
                )

            # æ£€æŸ¥æ˜¯å¦æœ‰ tool_call
            tool_calls = llm_response.get("tool_calls")
            assistant_content = llm_response.get("content", "")

            if not tool_calls:
                # LLM ä¸å†è°ƒç”¨å·¥å…·ï¼Œä»»åŠ¡å®Œæˆ
                return StepResult(
                    success=True,
                    message=assistant_content or "æ¡Œé¢æ“æ§ä»»åŠ¡å·²å®Œæˆ",
                    data={"iterations": iteration},
                )

            # å°† assistant æ¶ˆæ¯åŠ å…¥å†å²
            messages.append({
                "role": "assistant",
                "content": assistant_content,
                "tool_calls": tool_calls,
            })

            # ä¾æ¬¡æ‰§è¡Œæ¯ä¸ª tool_call
            for tc in tool_calls:
                func_name: str = tc.get("function", {}).get("name", "")
                func_args_raw: str = tc.get("function", {}).get("arguments", "{}")
                tc_id: str = tc.get("id", "")

                try:
                    func_args: Dict[str, Any] = json.loads(func_args_raw)
                except (json.JSONDecodeError, TypeError):
                    func_args = {}

                # æ‰§è¡Œå·¥å…·
                tool_fn = TOOL_REGISTRY.get(func_name)
                if tool_fn is None:
                    tool_result = f"æœªçŸ¥å·¥å…·: {func_name}"
                else:
                    try:
                        tool_result = await tool_fn(**func_args)
                    except Exception as e:
                        tool_result = f"å·¥å…·æ‰§è¡Œå¼‚å¸¸: {e}"

                # å®ˆå«æ£€æŸ¥
                action = self._guard.check(func_name, func_args, str(tool_result))
                if action == GuardAction.ABORT:
                    return StepResult(
                        success=False,
                        message=f"å®‰å…¨å®ˆå«ç»ˆæ­¢ï¼šæ£€æµ‹åˆ°å±é™©æ“ä½œæˆ–è¿‡å¤šåç¦»",
                        data={"iterations": iteration, "last_tool": func_name},
                    )
                elif action == GuardAction.SWITCH:
                    # æç¤º LLM åˆ‡æ¢ç›®æ ‡
                    tool_result = (
                        f"{tool_result}\n"
                        f"[å®ˆå«æç¤º] å½“å‰åº”ç”¨/ç½‘ç«™å¤šæ¬¡å¤±è´¥ï¼Œè¯·åˆ‡æ¢åˆ°å…¶ä»–æ›¿ä»£æ–¹æ¡ˆã€‚"
                    )

                # å°† tool ç»“æœå›å¡«æ¶ˆæ¯
                messages.append({
                    "role": "tool",
                    "tool_call_id": tc_id,
                    "content": str(tool_result),
                })

        return StepResult(
            success=False,
            message=f"è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({_MAX_ITERATIONS})ï¼Œä»»åŠ¡æœªå®Œæˆ",
            data={"iterations": _MAX_ITERATIONS},
        )

    async def _call_llm(self, messages: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """
        è°ƒç”¨ vLLM /v1/chat/completions è·å– LLM å“åº”

        é€šè¿‡ aiohttp ç›´æ¥è°ƒç”¨ï¼Œæ”¯æŒ tool_callã€‚

        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨

        Returns:
            Dict åŒ…å« content å’Œ tool_callsï¼Œæˆ– None è¡¨ç¤ºå¤±è´¥
        """
        try:
            import aiohttp
        except ImportError:
            # aiohttp å·²åœ¨ requirements.txt ä¸­ï¼Œä¸åº”å‘ç”Ÿ
            return None

        url = f"{EXECUTOR_LLM_URL}/v1/chat/completions"
        payload = {
            "model": EXECUTOR_LLM_MODEL,
            "messages": messages,
            "tools": TOOL_DEFINITIONS,
            "tool_choice": "auto",
        }
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {EXECUTOR_LLM_TOKEN}"
            }
            async with aiohttp.ClientSession() as session:
                async with session.post(
                        url,
                        json=payload,
                        headers=headers,
                        timeout=aiohttp.ClientTimeout(total=60),
                ) as resp:
                    if resp.status != 200:
                        return None
                    data = await resp.json()
                    choice = data.get("choices", [{}])[0]
                    msg = choice.get("message", {})
                    logger.info(f"ğŸª› DesktopExecutor summary: {msg}")

                    return {
                        "content": msg.get("content", ""),
                        "tool_calls": msg.get("tool_calls"),
                    }
        except Exception as exc:
            # è¿æ¥å¤±è´¥ã€è¶…æ—¶ç­‰ï¼Œè¿”å› None ç”±è°ƒç”¨æ–¹å¤„ç†
            _ = exc  # å®é™…éƒ¨ç½²æ—¶å¯æ¥å…¥æ—¥å¿—ç³»ç»Ÿ
            return None
